{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e24eddd-e95f-429b-b86f-d1a3d66001e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fbca1b-8513-475e-842f-8cadb8e1f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageToNumDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, answers_file=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.answers_file = answers_file\n",
    "\n",
    "        if self.answers_file is not None:\n",
    "            self.img_labels = pd.read_csv(answers_file)\n",
    "        else:\n",
    "            self.img_labels = None\n",
    "        \n",
    "        self.image_filenames = [file for file in os.listdir(img_dir) if file.endswith('.png')]\n",
    "        self.image_filenames.sort(key=lambda x: int(x.replace(\"img_\", \"\", 1).replace(\".png\", \"\", 1)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_filenames[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.img_labels is not None:\n",
    "            label = self.img_labels.iloc[idx, 1]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b82e1c15-4a8d-4199-b6b9-f0e964ee2b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "dataset = ImageToNumDataset(img_dir=\"C:/Users/rosti/Desktop/data/train_images_after_model\", transform=transform, answers_file=\"C:/Users/rosti/Desktop/data/train_answers.csv\")\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e9ace9b-0edb-43ce-bd37-8f2fbe5970bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 256, 256]              60\n",
      "       BatchNorm2d-2          [-1, 6, 256, 256]              12\n",
      "              ReLU-3          [-1, 6, 256, 256]               0\n",
      "         MaxPool2d-4          [-1, 6, 128, 128]               0\n",
      "            Conv2d-5         [-1, 12, 128, 128]             660\n",
      "       BatchNorm2d-6         [-1, 12, 128, 128]              24\n",
      "              ReLU-7         [-1, 12, 128, 128]               0\n",
      "         MaxPool2d-8           [-1, 12, 64, 64]               0\n",
      "            Conv2d-9           [-1, 24, 64, 64]           2,616\n",
      "      BatchNorm2d-10           [-1, 24, 64, 64]              48\n",
      "             ReLU-11           [-1, 24, 64, 64]               0\n",
      "        MaxPool2d-12           [-1, 24, 32, 32]               0\n",
      "           Conv2d-13           [-1, 48, 32, 32]          10,416\n",
      "      BatchNorm2d-14           [-1, 48, 32, 32]              96\n",
      "             ReLU-15           [-1, 48, 32, 32]               0\n",
      "        MaxPool2d-16           [-1, 48, 16, 16]               0\n",
      "           Linear-17                  [-1, 768]       9,437,952\n",
      "             ReLU-18                  [-1, 768]               0\n",
      "          Dropout-19                  [-1, 768]               0\n",
      "           Linear-20                   [-1, 48]          36,912\n",
      "           Linear-21                    [-1, 3]             147\n",
      "          Softmax-22                    [-1, 3]               0\n",
      "================================================================\n",
      "Total params: 9,488,943\n",
      "Trainable params: 9,488,943\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 18.30\n",
      "Params size (MB): 36.20\n",
      "Estimated Total Size (MB): 54.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "class EnhancedNoMaskModel(nn.Module):\n",
    "    \"\"\"\n",
    "   Расширенная модель нейронной сети для обработки изображений с увеличенным количеством сверточных слоев.\n",
    "\n",
    "   Attributes:\n",
    "       pool (nn.MaxPool2d): Операция пулинга для уменьшения размерности данных.\n",
    "       dropout (nn.Dropout): Операция dropout для регуляризации.\n",
    "       conv1 (nn.Conv2d): Первый сверточный слой.\n",
    "       conv2 (nn.Conv2d): Второй сверточный слой.\n",
    "       conv3 (nn.Conv2d): Третий сверточный слой.\n",
    "       conv4 (nn.Conv2d): Четвертый сверточный слой.\n",
    "       bn1 (nn.BatchNorm2d): Нормализация для первого сверточного слоя.\n",
    "       bn2 (nn.BatchNorm2d): Нормализация для второго сверточного слоя.\n",
    "       bn3 (nn.BatchNorm2d): Нормализация для третьего сверточного слоя.\n",
    "       bn4 (nn.BatchNorm2d): Нормализация для четвертого сверточного слоя.\n",
    "       relu (nn.ReLU): Функция активации ReLU для извлечения признаков.\n",
    "       input_liner (nn.Linear): Полносвязный слой для обработки входных данных.\n",
    "       liner1 (nn.Linear): Полносвязный слой для внутреннего представления.\n",
    "       output_liner (nn.Linear): Выходной полносвязный слой модели.\n",
    "       softmax (nn.Softmax): Функция Softmax для получения вероятностного распределения.\n",
    "   \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Инициализация сверточных слоев, операций и полносвязных слоев\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.bn3 = nn.BatchNorm2d(24)\n",
    "        self.bn4 = nn.BatchNorm2d(48)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.input_liner = nn.Linear(48 * 16 * 16, 48 * 16)\n",
    "        self.liner1 = nn.Linear(48 * 16, 48)\n",
    "        self.output_liner = nn.Linear(48, 3)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        # Выравнивание данных перед подачей на полносвязные слои\n",
    "        x = x.view(-1, 48 * 16 * 16)\n",
    "\n",
    "        x = self.relu(self.input_liner(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.liner1(x)\n",
    "        x = self.output_liner(x)\n",
    "\n",
    "        # Применение Softmax для получения вероятностного распределения\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = EnhancedNoMaskModel()\n",
    "\n",
    "summary(model, (1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c29d7bc-9f76-4136-853a-4ddae8670ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedNoMaskModel()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a91c487-3b2c-4b1c-b6df-2cc80176dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(loader):\n",
    "    \"\"\"\n",
    "    Расчет метрики F1 для модели на заданном загрузчике данных.\n",
    "\n",
    "    Args:\n",
    "        loader (DataLoader): Загрузчик данных для расчета метрики.\n",
    "\n",
    "    Returns:\n",
    "        float: Значение метрики F1 для модели на данных из загрузчика.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    return f1_score(all_labels, all_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "557bbf18-2d62-4497-8cbb-b921e49950a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 1.2223237191929537, F1-Score: 0.17148097203117832\n",
      "Model saved to output_models/model_main1.pth\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    f1 = calculate_f1(test_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}, F1-Score: {f1}\")\n",
    "    model_path = f\"output_models/model_main{epoch+1}.pth\" \n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451031d-3896-4440-b457-1c775d193a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
