{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e24eddd-e95f-429b-b86f-d1a3d66001e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fbca1b-8513-475e-842f-8cadb8e1f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageToNumDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, answers_file=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.answers_file = answers_file\n",
    "\n",
    "        if self.answers_file is not None:\n",
    "            self.img_labels = pd.read_csv(answers_file)\n",
    "        else:\n",
    "            self.img_labels = None\n",
    "        \n",
    "        self.image_filenames = [file for file in os.listdir(img_dir) if file.endswith('.png')]\n",
    "        self.image_filenames.sort(key=lambda x: int(x.replace(\"img_\", \"\", 1).replace(\".png\", \"\", 1)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_filenames[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.img_labels is not None:\n",
    "            label = self.img_labels.iloc[idx, 1]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b82e1c15-4a8d-4199-b6b9-f0e964ee2b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "dataset = ImageToNumDataset(img_dir=\"C:/Users/rosti/Desktop/data/train_images_after_model\", transform=transform, answers_file=\"C:/Users/rosti/Desktop/data/train_answers.csv\")\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e9ace9b-0edb-43ce-bd37-8f2fbe5970bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 256, 256]              60\n",
      "       BatchNorm2d-2          [-1, 6, 256, 256]              12\n",
      "              ReLU-3          [-1, 6, 256, 256]               0\n",
      "         MaxPool2d-4          [-1, 6, 128, 128]               0\n",
      "            Conv2d-5         [-1, 12, 128, 128]             660\n",
      "       BatchNorm2d-6         [-1, 12, 128, 128]              24\n",
      "              ReLU-7         [-1, 12, 128, 128]               0\n",
      "         MaxPool2d-8           [-1, 12, 64, 64]               0\n",
      "            Conv2d-9           [-1, 24, 64, 64]           2,616\n",
      "      BatchNorm2d-10           [-1, 24, 64, 64]              48\n",
      "             ReLU-11           [-1, 24, 64, 64]               0\n",
      "        MaxPool2d-12           [-1, 24, 32, 32]               0\n",
      "           Conv2d-13           [-1, 48, 32, 32]          10,416\n",
      "      BatchNorm2d-14           [-1, 48, 32, 32]              96\n",
      "             ReLU-15           [-1, 48, 32, 32]               0\n",
      "        MaxPool2d-16           [-1, 48, 16, 16]               0\n",
      "           Linear-17                  [-1, 768]       9,437,952\n",
      "             ReLU-18                  [-1, 768]               0\n",
      "          Dropout-19                  [-1, 768]               0\n",
      "           Linear-20                   [-1, 48]          36,912\n",
      "           Linear-21                    [-1, 3]             147\n",
      "          Softmax-22                    [-1, 3]               0\n",
      "================================================================\n",
      "Total params: 9,488,943\n",
      "Trainable params: 9,488,943\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 18.30\n",
      "Params size (MB): 36.20\n",
      "Estimated Total Size (MB): 54.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "class EnhancedNoMaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # Increase the number of convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.bn3 = nn.BatchNorm2d(24)\n",
    "        self.bn4 = nn.BatchNorm2d(48)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Adjusting the size for the linear layer input\n",
    "        self.input_liner = nn.Linear(48 * 16 * 16, 48 * 16)\n",
    "        self.liner1 = nn.Linear(48 * 16, 48)\n",
    "        self.output_liner = nn.Linear(48, 3)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        # Adjusting the flattening based on the new output size\n",
    "        x = x.view(-1, 48 * 16 * 16)\n",
    "\n",
    "        x = self.relu(self.input_liner(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.liner1(x)\n",
    "        x = self.output_liner(x)\n",
    "\n",
    "        # Applying Softmax to get probability distribution\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = EnhancedNoMaskModel()\n",
    "\n",
    "# Summary for input size (1, 256, 256)\n",
    "summary(model, (1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c29d7bc-9f76-4136-853a-4ddae8670ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedNoMaskModel()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a91c487-3b2c-4b1c-b6df-2cc80176dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    return f1_score(all_labels, all_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "557bbf18-2d62-4497-8cbb-b921e49950a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 1.2223237191929537, F1-Score: 0.17148097203117832\n",
      "Model saved to output_models/model_main1.pth\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    f1 = calculate_f1(test_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}, F1-Score: {f1}\")\n",
    "    model_path = f\"output_models/model_main{epoch+1}.pth\" \n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451031d-3896-4440-b457-1c775d193a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
