{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e24eddd-e95f-429b-b86f-d1a3d66001e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62fbca1b-8513-475e-842f-8cadb8e1f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageToNumDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, answers_file=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.answers_file = answers_file\n",
    "\n",
    "        if self.answers_file is not None:\n",
    "            self.img_labels = pd.read_csv(answers_file)\n",
    "        else:\n",
    "            self.img_labels = None\n",
    "        \n",
    "        self.image_filenames = [file for file in os.listdir(img_dir) if file.endswith('.png')]\n",
    "        self.image_filenames.sort(key=lambda x: int(x.replace(\"img_\", \"\", 1).replace(\".png\", \"\", 1)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_filenames[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.img_labels is not None:\n",
    "            label = self.img_labels.iloc[idx, 1]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82e1c15-4a8d-4199-b6b9-f0e964ee2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = ImageToNumDataset(img_dir=\"C:/Users/rosti/Desktop/data/train_images_after_model\", transform=transform, answers_file=\"C:/Users/rosti/Desktop/data/train_answers.csv\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e9ace9b-0edb-43ce-bd37-8f2fbe5970bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 256, 256]              60\n",
      "       BatchNorm2d-2          [-1, 6, 256, 256]              12\n",
      "              ReLU-3          [-1, 6, 256, 256]               0\n",
      "         MaxPool2d-4          [-1, 6, 128, 128]               0\n",
      "            Conv2d-5         [-1, 12, 128, 128]             660\n",
      "       BatchNorm2d-6         [-1, 12, 128, 128]              24\n",
      "              ReLU-7         [-1, 12, 128, 128]               0\n",
      "         MaxPool2d-8           [-1, 12, 64, 64]               0\n",
      "            Conv2d-9           [-1, 24, 64, 64]           2,616\n",
      "      BatchNorm2d-10           [-1, 24, 64, 64]              48\n",
      "             ReLU-11           [-1, 24, 64, 64]               0\n",
      "        MaxPool2d-12           [-1, 24, 32, 32]               0\n",
      "           Conv2d-13           [-1, 48, 32, 32]          10,416\n",
      "      BatchNorm2d-14           [-1, 48, 32, 32]              96\n",
      "             ReLU-15           [-1, 48, 32, 32]               0\n",
      "        MaxPool2d-16           [-1, 48, 16, 16]               0\n",
      "           Linear-17                  [-1, 768]       9,437,952\n",
      "             ReLU-18                  [-1, 768]               0\n",
      "          Dropout-19                  [-1, 768]               0\n",
      "           Linear-20                   [-1, 48]          36,912\n",
      "           Linear-21                    [-1, 3]             147\n",
      "          Softmax-22                    [-1, 3]               0\n",
      "================================================================\n",
      "Total params: 9,488,943\n",
      "Trainable params: 9,488,943\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 18.30\n",
      "Params size (MB): 36.20\n",
      "Estimated Total Size (MB): 54.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "class EnhancedNoMaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # Increase the number of convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.bn3 = nn.BatchNorm2d(24)\n",
    "        self.bn4 = nn.BatchNorm2d(48)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Adjusting the size for the linear layer input\n",
    "        self.input_liner = nn.Linear(48 * 16 * 16, 48 * 16)\n",
    "        self.liner1 = nn.Linear(48 * 16, 48)\n",
    "        self.output_liner = nn.Linear(48, 3)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        # Adjusting the flattening based on the new output size\n",
    "        x = x.view(-1, 48 * 16 * 16)\n",
    "\n",
    "        x = self.relu(self.input_liner(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.liner1(x)\n",
    "        x = self.output_liner(x)\n",
    "\n",
    "        # Applying Softmax to get probability distribution\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = EnhancedNoMaskModel()\n",
    "\n",
    "# Summary for input size (1, 256, 256)\n",
    "summary(model, (1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c29d7bc-9f76-4136-853a-4ddae8670ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedNoMaskModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "557bbf18-2d62-4497-8cbb-b921e49950a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 1.2025403205086203\n",
      "Epoch [2/1000], Loss: 1.2043859650106992\n",
      "Epoch [3/1000], Loss: 1.2043859537910013\n",
      "Epoch [4/1000], Loss: 1.203773222250097\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18364\\4058574678.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 492\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "print(\"Training Complete\")\n",
    "\n",
    "model_path = \"model_main.pth\" \n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451031d-3896-4440-b457-1c775d193a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
