{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.525582Z",
     "start_time": "2023-12-22T20:20:49.496831Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import random\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps', index=0)"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps:0\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "DEVICE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.547234Z",
     "start_time": "2023-12-22T20:20:49.528650Z"
    }
   },
   "id": "9cd43a1b8152cf4c",
   "execution_count": 215
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# устанавливаем seed, чтобы результаты не изменялись при не изменение чего-либо\n",
    "torch.manual_seed(666)\n",
    "random.seed(666)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.570551Z",
     "start_time": "2023-12-22T20:20:49.549541Z"
    }
   },
   "id": "25a0ab7fd63cf6dd",
   "execution_count": 216
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ImageToImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Создает набор данных для работы с парами изображений.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Путь к папке с входными изображениями.\n",
    "        target_dir (str, optional): Путь к папке с целевыми изображениями (по умолчанию: None).\n",
    "        transform (callable, optional): Преобразование изображений (по умолчанию: None).\n",
    "        mode (str): Режим работы ('train' или другой) (по умолчанию: 'train').\n",
    "\n",
    "    Attributes:\n",
    "        input_dir (str): Путь к папке с входными изображениями.\n",
    "        target_dir (str): Путь к папке с целевыми изображениями (если указан).\n",
    "        transform (callable): Функция преобразования изображений.\n",
    "        mode (str): Режим работы.\n",
    "        filenames (list): Список имен файлов изображений в папке с входными изображениями.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dir, target_dir=None, transform=None, mode='train'):\n",
    "        self.input_dir = input_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "        # Получение списка имен файлов в папке с входными изображениями\n",
    "        self.filenames = [f for f in os.listdir(input_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Формирование пути к входному изображению и его открытие\n",
    "        input_path = os.path.join(self.input_dir, self.filenames[idx])\n",
    "        input_image = Image.open(input_path).convert('L')\n",
    "\n",
    "        # Применение преобразования к входному изображению, если оно задано\n",
    "        if self.transform:\n",
    "            input_image = self.transform(input_image)\n",
    "\n",
    "        # Если режим 'train', получаем путь к целевому изображению и его открытие\n",
    "        if self.mode == 'train':\n",
    "            target_path = os.path.join(self.target_dir, self.filenames[idx])\n",
    "            target_image = Image.open(target_path).convert('L')\n",
    "            # Возвращаем пару изображений (входное и выходной)\n",
    "            return input_image, target_image\n",
    "        else:\n",
    "            # Возвращаем только входное изображение\n",
    "            return input_image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.571261Z",
     "start_time": "2023-12-22T20:20:49.555003Z"
    }
   },
   "id": "6bd121f059eab720",
   "execution_count": 217
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ImageToNumDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Создает набор данных изображений.\n",
    "\n",
    "    Parameters:\n",
    "        img_dir (str): Путь к папке с изображениями.\n",
    "        transform (callable, optional): Преобразование изображений (по умолчанию: None).\n",
    "        answers_file (str, optional): Путь к файлу с ответами (по умолчанию: None).\n",
    "\n",
    "    Attributes:\n",
    "        img_dir (str): Путь к папке с изображениями.\n",
    "        transform (callable): Функция преобразования изображений.\n",
    "        answers_file (str): Путь к файлу с ответами (если указан).\n",
    "        img_labels (DataFrame): DataFrame с метками изображений или None, если метки отсутствуют.\n",
    "        image_filenames (list): Список имен файлов изображений в папке.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, transform=None, answers_file=None):\n",
    "        # Инициализация класса ImageToNumDataset с указанием директории изображений,\n",
    "        # возможности трансформации и файла с ответами\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.answers_file = answers_file\n",
    "\n",
    "        # Если указан файл с ответами, загружаем его в виде DataFrame,\n",
    "        # иначе оставляем метки изображений пустыми\n",
    "        if self.answers_file is not None:\n",
    "            self.img_labels = pd.read_csv(answers_file)\n",
    "        else:\n",
    "            self.img_labels = None\n",
    "\n",
    "        # Получение списка имен файлов изображений в указанной директории и их сортировка по номеру\n",
    "        self.image_filenames = [file for file in os.listdir(img_dir) if file.endswith('.png')]\n",
    "        self.image_filenames.sort(key=lambda x: int(x.replace(\"img_\", \"\", 1).replace(\".png\", \"\", 1)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Получение имени файла изображения по индексу\n",
    "        img_name = self.image_filenames[idx]\n",
    "        # Формирование пути к изображению\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        # Открытие изображения и преобразование в оттенки серого\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "\n",
    "        # Применение трансформации (если указана)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Если имеются метки изображений, возвращаем изображение и соответствующую метку\n",
    "        if self.img_labels is not None:\n",
    "            label = self.img_labels.iloc[idx, 1]\n",
    "            return image, label\n",
    "        else:\n",
    "            # Если меток нет, возвращаем только изображение\n",
    "            return image\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.585660Z",
     "start_time": "2023-12-22T20:20:49.575618Z"
    }
   },
   "id": "b9b4b7d51f63a34e",
   "execution_count": 218
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class NoMaskModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Модель нейронной сети для обработки изображений.\n",
    "\n",
    "    Attributes:\n",
    "        dropout (nn.Dropout): Операция dropout для регуляризации.\n",
    "        input_liner (nn.Linear): Полносвязный слой для обработки входных данных.\n",
    "        softmax (nn.Softmax): Функция Softmax для получения вероятностного распределения.\n",
    "        output_liner (nn.Linear): Выходной полносвязный слой модели.\n",
    "        relu (nn.ReLU): Функция активации ReLU для извлечения признаков.\n",
    "        pool (nn.MaxPool2d): Операция пулинга для уменьшения размерности данных.\n",
    "        conv1 (nn.Conv2d): Первый сверточный слой.\n",
    "        conv2 (nn.Conv2d): Второй сверточный слой.\n",
    "        b1 (nn.BatchNorm2d): Нормализация для первого сверточного слоя.\n",
    "        b2 (nn.BatchNorm2d): Нормализация для второго сверточного слоя.\n",
    "        backend_liner1 (nn.Linear): Внутренний полносвязный слой.\n",
    "    \"\"\"\n",
    "\n",
    "    dropout: nn.Dropout\n",
    "    input_liner: nn.Linear\n",
    "    softmax: nn.Softmax\n",
    "    output_liner: nn.Linear\n",
    "    relu: nn.ReLU\n",
    "    pool: nn.MaxPool2d\n",
    "    conv1: nn.Conv2d\n",
    "    conv2: nn.Conv2d\n",
    "    b1: nn.BatchNorm2d\n",
    "    b2: nn.BatchNorm2d\n",
    "    backend_liner1: nn.Linear\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Инициализация слоев и операций\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # Определение сверточных слоев с указанием параметров\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=self.conv1.out_channels, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Инициализация слоев нормализации\n",
    "        self.bn1 = nn.BatchNorm2d(self.conv1.out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(self.conv2.out_channels)\n",
    "\n",
    "        # Инициализация функции активации ReLU\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Инициализация полносвязных слоев\n",
    "        self.input_liner = nn.Linear(self.conv2.out_channels * 64 * 64, 128)\n",
    "        self.output_liner = nn.Linear(self.input_liner.out_features, 3)\n",
    "\n",
    "        # Инициализация функции Softmax для получения вероятностного распределения\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Свертка, нормализация, применение функции активации и пулинг\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        # Выравнивание тензора перед подачей на полносвязный слой\n",
    "        x = x.view(-1, self.conv2.out_channels * 64 * 64)\n",
    "\n",
    "        # Проход через полносвязные слои с применением активации и dropout\n",
    "        x = self.relu(self.input_liner(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Выходной слой\n",
    "        x = self.output_liner(x)\n",
    "\n",
    "        # Применение Softmax для получения вероятностного распределения\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.593936Z",
     "start_time": "2023-12-22T20:20:49.582602Z"
    }
   },
   "id": "c1a8769c0f680a21",
   "execution_count": 219
  },
  {
   "cell_type": "markdown",
   "source": [
    "Первая модель"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aade20d45e190540"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms.v2 import ToDtype, Normalize, Compose, PILToTensor\n",
    "\n",
    "transform = Compose([\n",
    "    PILToTensor(),\n",
    "    ToDtype(torch.float32, scale=True),\n",
    "    Normalize((0.5,), (0.5,))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.595532Z",
     "start_time": "2023-12-22T20:20:49.586450Z"
    }
   },
   "id": "93717be86d939f72",
   "execution_count": 220
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Создание датасета \n",
    "dataset = ImageToNumDataset(\"data/train_images\", answers_file=\"data/train_answers.csv\", transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.663552Z",
     "start_time": "2023-12-22T20:20:49.597110Z"
    }
   },
   "id": "93c4208bb4abe0b7",
   "execution_count": 221
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "train_dataset, validation_dataset = random_split(dataset, (0.8, 0.2))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2**5, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=2**5, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.664294Z",
     "start_time": "2023-12-22T20:20:49.650532Z"
    }
   },
   "id": "3331006d57a84e61",
   "execution_count": 222
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NoMaskModel()\n",
    "model = model.to(DEVICE)\n",
    "# загрузка модели\n",
    "model.load_state_dict(torch.load(\"models/model.pt\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.984607Z",
     "start_time": "2023-12-22T20:20:49.651218Z"
    }
   },
   "id": "6dba8b834a6a90b0",
   "execution_count": 223
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "# Определение функции потерь для задачи классификации\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Инициализация оптимизатора для обновления параметров модели с использованием алгоритма Adam\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.993840Z",
     "start_time": "2023-12-22T20:20:49.986879Z"
    }
   },
   "id": "a101f83ad938e956",
   "execution_count": 224
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.engine import create_supervised_trainer, create_supervised_evaluator\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=DEVICE)\n",
    "evaluator = create_supervised_evaluator(model, metrics={'accuracy': Accuracy(), 'nll': Loss(criterion)}, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:49.995434Z",
     "start_time": "2023-12-22T20:20:49.992463Z"
    }
   },
   "id": "f1b7a4546f420f18",
   "execution_count": 225
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Сбор потерь и метрик для построения графиков\n",
    "train_loss_values = []\n",
    "validation_loss_values = []\n",
    "validation_accuracy_values = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:50.001357Z",
     "start_time": "2023-12-22T20:20:49.995559Z"
    }
   },
   "id": "1f53dedd2bc85c49",
   "execution_count": 226
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logging.getLogger(\"ignite.engine.engine.Engine\").setLevel(logging.WARNING)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:50.002085Z",
     "start_time": "2023-12-22T20:20:49.998623Z"
    }
   },
   "id": "b967f870860c7aa3",
   "execution_count": 227
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:50.004104Z",
     "start_time": "2023-12-22T20:20:50.000823Z"
    }
   },
   "id": "612604e2180b2a03",
   "execution_count": 228
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import datetime\n",
    "from ignite.engine import Events\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_STARTED)\n",
    "def log_training_start(engine):\n",
    "    logging.info(f\"Starting learning at epoch {engine.state.epoch} in {datetime.datetime.now()}\")\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    logging.info(f\"End learning at epoch {engine.state.epoch} in {datetime.datetime.now()}\")\n",
    "    logging.info(f\"Starting validation on epoch {engine.state.epoch}\")\n",
    "    # Запуск оценки модели на валидационном наборе данных\n",
    "    evaluator.run(validation_dataloader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    # Сбор и вывод средней точности и потерь на валидационном наборе\n",
    "    validation_loss_values.append(metrics['nll'])\n",
    "    validation_accuracy_values.append(metrics['accuracy'])\n",
    "    logging.info(\n",
    "        f\"Validation Results - Epoch: {engine.state.epoch}  \"\n",
    "        f\"Avg accuracy: {metrics['accuracy']:.3f} \"\n",
    "        f\"Avg loss: {metrics['nll']:.3f}\"\n",
    "    )\n",
    "    logging.info(f\"End of validation on epoch {engine.state.epoch}\")\n",
    "    torch.save(model.state_dict(), \"models/model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:20:50.010480Z",
     "start_time": "2023-12-22T20:20:50.005130Z"
    }
   },
   "id": "83c4a690602ee19e",
   "execution_count": 229
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting learning at epoch 1 in 2023-12-22 23:20:50.008104\n",
      "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[230], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:898\u001B[0m, in \u001B[0;36mEngine.run\u001B[0;34m(self, data, max_epochs, epoch_length, seed)\u001B[0m\n\u001B[1;32m    895\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mdataloader \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m    897\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minterrupt_resume_enabled:\n\u001B[0;32m--> 898\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_internal_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    899\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    900\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_legacy()\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:941\u001B[0m, in \u001B[0;36mEngine._internal_run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    939\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_generator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_as_gen()\n\u001B[1;32m    940\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 941\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_internal_run_generator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    942\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m out:\n\u001B[1;32m    943\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_generator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:999\u001B[0m, in \u001B[0;36mEngine._internal_run_as_gen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    997\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    998\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEngine run is terminating due to exception: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 999\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_exception\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1001\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1002\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:644\u001B[0m, in \u001B[0;36mEngine._handle_exception\u001B[0;34m(self, e)\u001B[0m\n\u001B[1;32m    642\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mEXCEPTION_RAISED, e)\n\u001B[1;32m    643\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 644\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:965\u001B[0m, in \u001B[0;36mEngine._internal_run_as_gen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    962\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    963\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setup_engine()\n\u001B[0;32m--> 965\u001B[0m epoch_time_taken \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_once_on_dataset_as_gen()\n\u001B[1;32m    967\u001B[0m \u001B[38;5;66;03m# time is available for handlers but must be updated after fire\u001B[39;00m\n\u001B[1;32m    968\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mtimes[Events\u001B[38;5;241m.\u001B[39mEPOCH_COMPLETED\u001B[38;5;241m.\u001B[39mname] \u001B[38;5;241m=\u001B[39m epoch_time_taken\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:1074\u001B[0m, in \u001B[0;36mEngine._run_once_on_dataset_as_gen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mITERATION_STARTED)\n\u001B[1;32m   1072\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_terminate_or_interrupt()\n\u001B[0;32m-> 1074\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mITERATION_COMPLETED)\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_terminate_or_interrupt()\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/__init__.py:117\u001B[0m, in \u001B[0;36msupervised_training_step.<locals>.update\u001B[0;34m(engine, batch)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gradient_accumulation_steps \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    116\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss \u001B[38;5;241m/\u001B[39m gradient_accumulation_steps\n\u001B[0;32m--> 117\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m engine\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39miteration \u001B[38;5;241m%\u001B[39m gradient_accumulation_steps \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    119\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run(train_dataloader, max_epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:21:01.206099Z",
     "start_time": "2023-12-22T20:20:50.008830Z"
    }
   },
   "id": "49a8ea024362a5ad",
   "execution_count": 230
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Графики обучения\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_values, label='Training Loss')\n",
    "plt.plot(validation_loss_values, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(validation_accuracy_values, label='Validation Accuracy', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T20:21:01.206566Z"
    }
   },
   "id": "d5ef1cf0f834f705",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "# устанавливаем seed, чтобы результаты не изменялись при не изменение чего-либо\n",
    "torch.manual_seed(666)\n",
    "random.seed(666)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "test_model = NoMaskModel()\n",
    "test_model = test_model.to(DEVICE)\n",
    "test_model.load_state_dict(torch.load(\"models/model.pt\"))\n",
    "test_dataset = ImageToNumDataset(\"data/test_images\", transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:21:01.213624Z",
     "start_time": "2023-12-22T20:21:01.207617Z"
    }
   },
   "id": "8a713c4761014ec9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Генерация файлов ответа\n",
    "test_model.eval()\n",
    "len_dataset = len(test_dataset)\n",
    "with open(\"answer.csv\", \"w\") as file:\n",
    "    writer = csv.writer(file, delimiter=\",\")\n",
    "    writer.writerow([\"id\", \"target_feature\"])\n",
    "    for index, image in enumerate(test_dataset):\n",
    "        with torch.no_grad():\n",
    "            pred_y = test_model(image.unsqueeze(0))\n",
    "        answer = max(((n, i) for i, n in enumerate(pred_y[0])), key=lambda x: x[0])[1]\n",
    "        writer.writerow([index, answer])\n",
    "        if index % 10 == 0 or index % 10 == 9:\n",
    "            print(f\"{(index / len_dataset) * 100:.2f}%\")\n",
    "print(\"100%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T20:21:01.208851Z"
    }
   },
   "id": "a5a5b731a8e6bdd3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вторая модель"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0f29a6609a12b6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ImageToImageDataset(Dataset):\n",
    "    def __init__(self, input_dir, target_dir=None, transform=None, target_transform=None, mode='train'):\n",
    "        self.input_dir = input_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform or transform\n",
    "        self.mode = mode\n",
    "        self.filenames = [f for f in os.listdir(input_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path = os.path.join(self.input_dir, self.filenames[idx])\n",
    "        input_image = Image.open(input_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            input_image = self.transform(input_image)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            target_path = os.path.join(self.target_dir, self.filenames[idx])\n",
    "            target_image = Image.open(target_path).convert('L')\n",
    "\n",
    "            if self.target_transform:\n",
    "                target_image = self.target_transform(target_image)\n",
    "\n",
    "            return input_image, target_image\n",
    "        else:\n",
    "            return input_image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T20:21:01.209913Z"
    }
   },
   "id": "9b58613da512a6db",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "def save_image(tensor, filename):\n",
    "    \"\"\" Сохраняет тензор как изображение. \"\"\"\n",
    "    torchvision.utils.save_image(tensor, filename)\n",
    "\n",
    "# Определение модели\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Простая сверточная нейронная сеть.\n",
    "\n",
    "    Attributes:\n",
    "        conv1 (nn.Conv2d): Первый сверточный слой.\n",
    "        conv2 (nn.Conv2d): Второй сверточный слой.\n",
    "        conv3 (nn.Conv2d): Третий сверточный слой.\n",
    "        relu (nn.ReLU): Функция активации ReLU для извлечения признаков.\n",
    "        sigmoid (nn.Sigmoid): Функция активации Sigmoid для создания вероятностного вывода.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Инициализация сверточных слоев и функций активации\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 1, 3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Проход данных через сверточные слои и функции активации\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.sigmoid(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "# Параметры\n",
    "num_epochs = 6\n",
    "batch_size = 4\n",
    "learning_rate = 0.00001\n",
    "\n",
    "# Подготовка данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Нормализация если нужна\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Только преобразование в тензор для масок\n",
    "])\n",
    "\n",
    "train_dataset = ImageToImageDataset(input_dir=\"data/train_images\", target_dir=\"data/train_lung_masks\", transform=transform, target_transform =target_transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = SimpleCNN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Обучение модели\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "model_path = \"model_mask.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T20:21:01.211056Z"
    }
   },
   "id": "9346f048f3f8204a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "dataset = ImageToNumDataset(img_dir=\"data/train_images_after_model\", transform=transform, answers_file=\"data/train_answers.csv\")\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T20:21:01.212090Z"
    }
   },
   "id": "b2135c94f28a0f13",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "class EnhancedNoMaskModel(nn.Module):\n",
    "    \"\"\"\n",
    "   Расширенная модель нейронной сети для обработки изображений с увеличенным количеством сверточных слоев.\n",
    "\n",
    "   Attributes:\n",
    "       pool (nn.MaxPool2d): Операция пулинга для уменьшения размерности данных.\n",
    "       dropout (nn.Dropout): Операция dropout для регуляризации.\n",
    "       conv1 (nn.Conv2d): Первый сверточный слой.\n",
    "       conv2 (nn.Conv2d): Второй сверточный слой.\n",
    "       conv3 (nn.Conv2d): Третий сверточный слой.\n",
    "       conv4 (nn.Conv2d): Четвертый сверточный слой.\n",
    "       bn1 (nn.BatchNorm2d): Нормализация для первого сверточного слоя.\n",
    "       bn2 (nn.BatchNorm2d): Нормализация для второго сверточного слоя.\n",
    "       bn3 (nn.BatchNorm2d): Нормализация для третьего сверточного слоя.\n",
    "       bn4 (nn.BatchNorm2d): Нормализация для четвертого сверточного слоя.\n",
    "       relu (nn.ReLU): Функция активации ReLU для извлечения признаков.\n",
    "       input_liner (nn.Linear): Полносвязный слой для обработки входных данных.\n",
    "       liner1 (nn.Linear): Полносвязный слой для внутреннего представления.\n",
    "       output_liner (nn.Linear): Выходной полносвязный слой модели.\n",
    "       softmax (nn.Softmax): Функция Softmax для получения вероятностного распределения.\n",
    "   \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Инициализация сверточных слоев, операций и полносвязных слоев\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.bn3 = nn.BatchNorm2d(24)\n",
    "        self.bn4 = nn.BatchNorm2d(48)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.input_liner = nn.Linear(48 * 16 * 16, 48 * 16)\n",
    "        self.liner1 = nn.Linear(48 * 16, 48)\n",
    "        self.output_liner = nn.Linear(48, 3)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.pool(self.relu(x))\n",
    "\n",
    "        # Выравнивание данных перед подачей на полносвязные слои\n",
    "        x = x.view(-1, 48 * 16 * 16)\n",
    "\n",
    "        x = self.relu(self.input_liner(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.liner1(x)\n",
    "        x = self.output_liner(x)\n",
    "\n",
    "        # Применение Softmax для получения вероятностного распределения\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = EnhancedNoMaskModel()\n",
    "\n",
    "summary(model, (1, 256, 256))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T20:21:01.212961Z"
    }
   },
   "id": "ded0da49256a4a0a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = EnhancedNoMaskModel()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T20:21:01.213614Z"
    }
   },
   "id": "7168dded9caf3dfa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def calculate_f1(loader):\n",
    "    \"\"\"\n",
    "    Расчет метрики F1 для модели на заданном загрузчике данных.\n",
    "\n",
    "    Args:\n",
    "        loader (DataLoader): Загрузчик данных для расчета метрики.\n",
    "\n",
    "    Returns:\n",
    "        float: Значение метрики F1 для модели на данных из загрузчика.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    return f1_score(all_labels, all_preds, average='macro')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:21:01.215751Z",
     "start_time": "2023-12-22T20:21:01.214350Z"
    }
   },
   "id": "354815c656e9bd0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Обучение\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    f1 = calculate_f1(test_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}, F1-Score: {f1}\")\n",
    "    model_path = f\"output_models/model_main{epoch+1}.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "print(\"Training Complete\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T20:21:01.215006Z"
    }
   },
   "id": "2d911ac2cf4e76e7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T20:21:01.215689Z"
    }
   },
   "id": "22454fc33bbb6208"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
