{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Step [100/6750], Loss: 0.4247\n",
      "Epoch [1/6], Step [200/6750], Loss: 0.3752\n",
      "Epoch [1/6], Step [300/6750], Loss: 0.4444\n",
      "Epoch [1/6], Step [400/6750], Loss: 0.4063\n",
      "Epoch [1/6], Step [500/6750], Loss: 0.4648\n",
      "Epoch [1/6], Step [600/6750], Loss: 0.3335\n",
      "Epoch [1/6], Step [700/6750], Loss: 0.4067\n",
      "Epoch [1/6], Step [800/6750], Loss: 0.4246\n",
      "Epoch [1/6], Step [900/6750], Loss: 0.4453\n",
      "Epoch [1/6], Step [1000/6750], Loss: 0.4185\n",
      "Epoch [1/6], Step [1100/6750], Loss: 0.4509\n",
      "Epoch [1/6], Step [1200/6750], Loss: 0.4479\n",
      "Epoch [1/6], Step [1300/6750], Loss: 0.3825\n",
      "Epoch [1/6], Step [1400/6750], Loss: 0.3538\n",
      "Epoch [1/6], Step [1500/6750], Loss: 0.4054\n",
      "Epoch [1/6], Step [1600/6750], Loss: 0.4167\n",
      "Epoch [1/6], Step [1700/6750], Loss: 0.4212\n",
      "Epoch [1/6], Step [1800/6750], Loss: 0.4278\n",
      "Epoch [1/6], Step [1900/6750], Loss: 0.3742\n",
      "Epoch [1/6], Step [2000/6750], Loss: 0.4307\n",
      "Epoch [1/6], Step [2100/6750], Loss: 0.3613\n",
      "Epoch [1/6], Step [2200/6750], Loss: 0.3383\n",
      "Epoch [1/6], Step [2300/6750], Loss: 0.3861\n",
      "Epoch [1/6], Step [2400/6750], Loss: 0.3749\n",
      "Epoch [1/6], Step [2500/6750], Loss: 0.3759\n",
      "Epoch [1/6], Step [2600/6750], Loss: 0.3969\n",
      "Epoch [1/6], Step [2700/6750], Loss: 0.4244\n",
      "Epoch [1/6], Step [2800/6750], Loss: 0.3397\n",
      "Epoch [1/6], Step [2900/6750], Loss: 0.4059\n",
      "Epoch [1/6], Step [3000/6750], Loss: 0.3667\n",
      "Epoch [1/6], Step [3100/6750], Loss: 0.3435\n",
      "Epoch [1/6], Step [3200/6750], Loss: 0.3772\n",
      "Epoch [1/6], Step [3300/6750], Loss: 0.3357\n",
      "Epoch [1/6], Step [3400/6750], Loss: 0.3050\n",
      "Epoch [1/6], Step [3500/6750], Loss: 0.3985\n",
      "Epoch [1/6], Step [3600/6750], Loss: 0.3958\n",
      "Epoch [1/6], Step [3700/6750], Loss: 0.3998\n",
      "Epoch [1/6], Step [3800/6750], Loss: 0.4074\n",
      "Epoch [1/6], Step [3900/6750], Loss: 0.3150\n",
      "Epoch [1/6], Step [4000/6750], Loss: 0.3484\n",
      "Epoch [1/6], Step [4100/6750], Loss: 0.3490\n",
      "Epoch [1/6], Step [4200/6750], Loss: 0.3017\n",
      "Epoch [1/6], Step [4300/6750], Loss: 0.4738\n",
      "Epoch [1/6], Step [4400/6750], Loss: 0.3356\n",
      "Epoch [1/6], Step [4500/6750], Loss: 0.3783\n",
      "Epoch [1/6], Step [4600/6750], Loss: 0.3688\n",
      "Epoch [1/6], Step [4700/6750], Loss: 0.3293\n",
      "Epoch [1/6], Step [4800/6750], Loss: 0.3420\n",
      "Epoch [1/6], Step [4900/6750], Loss: 0.3716\n",
      "Epoch [1/6], Step [5000/6750], Loss: 0.2877\n",
      "Epoch [1/6], Step [5100/6750], Loss: 0.3455\n",
      "Epoch [1/6], Step [5200/6750], Loss: 0.3162\n",
      "Epoch [1/6], Step [5300/6750], Loss: 0.4646\n",
      "Epoch [1/6], Step [5400/6750], Loss: 0.3443\n",
      "Epoch [1/6], Step [5500/6750], Loss: 0.3272\n",
      "Epoch [1/6], Step [5600/6750], Loss: 0.4002\n",
      "Epoch [1/6], Step [5700/6750], Loss: 0.3655\n",
      "Epoch [1/6], Step [5800/6750], Loss: 0.3204\n",
      "Epoch [1/6], Step [5900/6750], Loss: 0.3181\n",
      "Epoch [1/6], Step [6000/6750], Loss: 0.3406\n",
      "Epoch [1/6], Step [6100/6750], Loss: 0.3612\n",
      "Epoch [1/6], Step [6200/6750], Loss: 0.3571\n",
      "Epoch [1/6], Step [6300/6750], Loss: 0.3406\n",
      "Epoch [1/6], Step [6400/6750], Loss: 0.3656\n",
      "Epoch [1/6], Step [6500/6750], Loss: 0.3100\n",
      "Epoch [1/6], Step [6600/6750], Loss: 0.3837\n",
      "Epoch [1/6], Step [6700/6750], Loss: 0.4115\n",
      "Epoch [2/6], Step [100/6750], Loss: 0.3300\n",
      "Epoch [2/6], Step [200/6750], Loss: 0.3305\n",
      "Epoch [2/6], Step [300/6750], Loss: 0.3103\n",
      "Epoch [2/6], Step [400/6750], Loss: 0.3423\n",
      "Epoch [2/6], Step [500/6750], Loss: 0.3250\n",
      "Epoch [2/6], Step [600/6750], Loss: 0.3457\n",
      "Epoch [2/6], Step [700/6750], Loss: 0.3186\n",
      "Epoch [2/6], Step [800/6750], Loss: 0.2779\n",
      "Epoch [2/6], Step [900/6750], Loss: 0.3048\n",
      "Epoch [2/6], Step [1000/6750], Loss: 0.3323\n",
      "Epoch [2/6], Step [1100/6750], Loss: 0.3354\n",
      "Epoch [2/6], Step [1200/6750], Loss: 0.3144\n",
      "Epoch [2/6], Step [1300/6750], Loss: 0.3102\n",
      "Epoch [2/6], Step [1400/6750], Loss: 0.2792\n",
      "Epoch [2/6], Step [1500/6750], Loss: 0.2811\n",
      "Epoch [2/6], Step [1600/6750], Loss: 0.2986\n",
      "Epoch [2/6], Step [1700/6750], Loss: 0.2791\n",
      "Epoch [2/6], Step [1800/6750], Loss: 0.4103\n",
      "Epoch [2/6], Step [1900/6750], Loss: 0.2957\n",
      "Epoch [2/6], Step [2000/6750], Loss: 0.4195\n",
      "Epoch [2/6], Step [2100/6750], Loss: 0.3662\n",
      "Epoch [2/6], Step [2200/6750], Loss: 0.2995\n",
      "Epoch [2/6], Step [2300/6750], Loss: 0.4562\n",
      "Epoch [2/6], Step [2400/6750], Loss: 0.2681\n",
      "Epoch [2/6], Step [2500/6750], Loss: 0.2916\n",
      "Epoch [2/6], Step [2600/6750], Loss: 0.2524\n",
      "Epoch [2/6], Step [2700/6750], Loss: 0.3114\n",
      "Epoch [2/6], Step [2800/6750], Loss: 0.2977\n",
      "Epoch [2/6], Step [2900/6750], Loss: 0.2745\n",
      "Epoch [2/6], Step [3000/6750], Loss: 0.2717\n",
      "Epoch [2/6], Step [3100/6750], Loss: 0.2720\n",
      "Epoch [2/6], Step [3200/6750], Loss: 0.2836\n",
      "Epoch [2/6], Step [3300/6750], Loss: 0.2910\n",
      "Epoch [2/6], Step [3400/6750], Loss: 0.3229\n",
      "Epoch [2/6], Step [3500/6750], Loss: 0.3647\n",
      "Epoch [2/6], Step [3600/6750], Loss: 0.2885\n",
      "Epoch [2/6], Step [3700/6750], Loss: 0.3382\n",
      "Epoch [2/6], Step [3800/6750], Loss: 0.2952\n",
      "Epoch [2/6], Step [3900/6750], Loss: 0.2841\n",
      "Epoch [2/6], Step [4000/6750], Loss: 0.3393\n",
      "Epoch [2/6], Step [4100/6750], Loss: 0.2771\n",
      "Epoch [2/6], Step [4200/6750], Loss: 0.2544\n",
      "Epoch [2/6], Step [4300/6750], Loss: 0.3485\n",
      "Epoch [2/6], Step [4400/6750], Loss: 0.2997\n",
      "Epoch [2/6], Step [4500/6750], Loss: 0.2243\n",
      "Epoch [2/6], Step [4600/6750], Loss: 0.2490\n",
      "Epoch [2/6], Step [4700/6750], Loss: 0.3097\n",
      "Epoch [2/6], Step [4800/6750], Loss: 0.2359\n",
      "Epoch [2/6], Step [4900/6750], Loss: 0.3201\n",
      "Epoch [2/6], Step [5000/6750], Loss: 0.2783\n",
      "Epoch [2/6], Step [5100/6750], Loss: 0.2667\n",
      "Epoch [2/6], Step [5200/6750], Loss: 0.2713\n",
      "Epoch [2/6], Step [5300/6750], Loss: 0.3024\n",
      "Epoch [2/6], Step [5400/6750], Loss: 0.2725\n",
      "Epoch [2/6], Step [5500/6750], Loss: 0.2733\n",
      "Epoch [2/6], Step [5600/6750], Loss: 0.2969\n",
      "Epoch [2/6], Step [5700/6750], Loss: 0.3272\n",
      "Epoch [2/6], Step [5800/6750], Loss: 0.2683\n",
      "Epoch [2/6], Step [5900/6750], Loss: 0.2520\n",
      "Epoch [2/6], Step [6000/6750], Loss: 0.2790\n",
      "Epoch [2/6], Step [6100/6750], Loss: 0.2822\n",
      "Epoch [2/6], Step [6200/6750], Loss: 0.2902\n",
      "Epoch [2/6], Step [6300/6750], Loss: 0.3127\n",
      "Epoch [2/6], Step [6400/6750], Loss: 0.2407\n",
      "Epoch [2/6], Step [6500/6750], Loss: 0.3046\n",
      "Epoch [2/6], Step [6600/6750], Loss: 0.2901\n",
      "Epoch [2/6], Step [6700/6750], Loss: 0.3734\n",
      "Epoch [3/6], Step [100/6750], Loss: 0.3915\n",
      "Epoch [3/6], Step [200/6750], Loss: 0.2916\n",
      "Epoch [3/6], Step [300/6750], Loss: 0.3690\n",
      "Epoch [3/6], Step [400/6750], Loss: 0.2905\n",
      "Epoch [3/6], Step [500/6750], Loss: 0.2061\n",
      "Epoch [3/6], Step [600/6750], Loss: 0.3327\n",
      "Epoch [3/6], Step [700/6750], Loss: 0.1939\n",
      "Epoch [3/6], Step [800/6750], Loss: 0.2639\n",
      "Epoch [3/6], Step [900/6750], Loss: 0.2812\n",
      "Epoch [3/6], Step [1000/6750], Loss: 0.4101\n",
      "Epoch [3/6], Step [1100/6750], Loss: 0.3270\n",
      "Epoch [3/6], Step [1200/6750], Loss: 0.2604\n",
      "Epoch [3/6], Step [1300/6750], Loss: 0.2659\n",
      "Epoch [3/6], Step [1400/6750], Loss: 0.2391\n",
      "Epoch [3/6], Step [1500/6750], Loss: 0.5143\n",
      "Epoch [3/6], Step [1600/6750], Loss: 0.2788\n",
      "Epoch [3/6], Step [1700/6750], Loss: 0.3121\n",
      "Epoch [3/6], Step [1800/6750], Loss: 0.2696\n",
      "Epoch [3/6], Step [1900/6750], Loss: 0.2832\n",
      "Epoch [3/6], Step [2000/6750], Loss: 0.2680\n",
      "Epoch [3/6], Step [2100/6750], Loss: 0.3114\n",
      "Epoch [3/6], Step [2200/6750], Loss: 0.2994\n",
      "Epoch [3/6], Step [2300/6750], Loss: 0.2693\n",
      "Epoch [3/6], Step [2400/6750], Loss: 0.4090\n",
      "Epoch [3/6], Step [2500/6750], Loss: 0.2236\n",
      "Epoch [3/6], Step [2600/6750], Loss: 0.2529\n",
      "Epoch [3/6], Step [2700/6750], Loss: 0.2093\n",
      "Epoch [3/6], Step [2800/6750], Loss: 0.2979\n",
      "Epoch [3/6], Step [2900/6750], Loss: 0.2702\n",
      "Epoch [3/6], Step [3000/6750], Loss: 0.2921\n",
      "Epoch [3/6], Step [3100/6750], Loss: 0.2715\n",
      "Epoch [3/6], Step [3200/6750], Loss: 0.3070\n",
      "Epoch [3/6], Step [3300/6750], Loss: 0.3117\n",
      "Epoch [3/6], Step [3400/6750], Loss: 0.2589\n",
      "Epoch [3/6], Step [3500/6750], Loss: 0.2898\n",
      "Epoch [3/6], Step [3600/6750], Loss: 0.2308\n",
      "Epoch [3/6], Step [3700/6750], Loss: 0.4028\n",
      "Epoch [3/6], Step [3800/6750], Loss: 0.2842\n",
      "Epoch [3/6], Step [3900/6750], Loss: 0.3277\n",
      "Epoch [3/6], Step [4000/6750], Loss: 0.2846\n",
      "Epoch [3/6], Step [4100/6750], Loss: 0.2689\n",
      "Epoch [3/6], Step [4200/6750], Loss: 0.3571\n",
      "Epoch [3/6], Step [4300/6750], Loss: 0.2609\n",
      "Epoch [3/6], Step [4400/6750], Loss: 0.2195\n",
      "Epoch [3/6], Step [4500/6750], Loss: 0.3348\n",
      "Epoch [3/6], Step [4600/6750], Loss: 0.2811\n",
      "Epoch [3/6], Step [4700/6750], Loss: 0.3371\n",
      "Epoch [3/6], Step [4800/6750], Loss: 0.3009\n",
      "Epoch [3/6], Step [4900/6750], Loss: 0.3035\n",
      "Epoch [3/6], Step [5000/6750], Loss: 0.3032\n",
      "Epoch [3/6], Step [5100/6750], Loss: 0.2252\n",
      "Epoch [3/6], Step [5200/6750], Loss: 0.3545\n",
      "Epoch [3/6], Step [5300/6750], Loss: 0.2509\n",
      "Epoch [3/6], Step [5400/6750], Loss: 0.2476\n",
      "Epoch [3/6], Step [5500/6750], Loss: 0.2483\n",
      "Epoch [3/6], Step [5600/6750], Loss: 0.3519\n",
      "Epoch [3/6], Step [5700/6750], Loss: 0.2572\n",
      "Epoch [3/6], Step [5800/6750], Loss: 0.2944\n",
      "Epoch [3/6], Step [5900/6750], Loss: 0.3641\n",
      "Epoch [3/6], Step [6000/6750], Loss: 0.2634\n",
      "Epoch [3/6], Step [6100/6750], Loss: 0.3240\n",
      "Epoch [3/6], Step [6200/6750], Loss: 0.2402\n",
      "Epoch [3/6], Step [6300/6750], Loss: 0.2722\n",
      "Epoch [3/6], Step [6400/6750], Loss: 0.3134\n",
      "Epoch [3/6], Step [6500/6750], Loss: 0.2805\n",
      "Epoch [3/6], Step [6600/6750], Loss: 0.2618\n",
      "Epoch [3/6], Step [6700/6750], Loss: 0.3567\n",
      "Epoch [4/6], Step [100/6750], Loss: 0.2215\n",
      "Epoch [4/6], Step [200/6750], Loss: 0.2740\n",
      "Epoch [4/6], Step [300/6750], Loss: 0.3022\n",
      "Epoch [4/6], Step [400/6750], Loss: 0.2896\n",
      "Epoch [4/6], Step [500/6750], Loss: 0.2799\n",
      "Epoch [4/6], Step [600/6750], Loss: 0.3362\n",
      "Epoch [4/6], Step [700/6750], Loss: 0.2893\n",
      "Epoch [4/6], Step [800/6750], Loss: 0.2339\n",
      "Epoch [4/6], Step [900/6750], Loss: 0.2477\n",
      "Epoch [4/6], Step [1000/6750], Loss: 0.3158\n",
      "Epoch [4/6], Step [1100/6750], Loss: 0.3018\n",
      "Epoch [4/6], Step [1200/6750], Loss: 0.2712\n",
      "Epoch [4/6], Step [1300/6750], Loss: 0.2655\n",
      "Epoch [4/6], Step [1400/6750], Loss: 0.2826\n",
      "Epoch [4/6], Step [1500/6750], Loss: 0.3414\n",
      "Epoch [4/6], Step [1600/6750], Loss: 0.2366\n",
      "Epoch [4/6], Step [1700/6750], Loss: 0.2769\n",
      "Epoch [4/6], Step [1800/6750], Loss: 0.2788\n",
      "Epoch [4/6], Step [1900/6750], Loss: 0.2911\n",
      "Epoch [4/6], Step [2000/6750], Loss: 0.2204\n",
      "Epoch [4/6], Step [2100/6750], Loss: 0.2751\n",
      "Epoch [4/6], Step [2200/6750], Loss: 0.2775\n",
      "Epoch [4/6], Step [2300/6750], Loss: 0.2787\n",
      "Epoch [4/6], Step [2400/6750], Loss: 0.2562\n",
      "Epoch [4/6], Step [2500/6750], Loss: 0.3357\n",
      "Epoch [4/6], Step [2600/6750], Loss: 0.2511\n",
      "Epoch [4/6], Step [2700/6750], Loss: 0.2576\n",
      "Epoch [4/6], Step [2800/6750], Loss: 0.2718\n",
      "Epoch [4/6], Step [2900/6750], Loss: 0.3106\n",
      "Epoch [4/6], Step [3000/6750], Loss: 0.2721\n",
      "Epoch [4/6], Step [3100/6750], Loss: 0.2814\n",
      "Epoch [4/6], Step [3200/6750], Loss: 0.2966\n",
      "Epoch [4/6], Step [3300/6750], Loss: 0.3124\n",
      "Epoch [4/6], Step [3400/6750], Loss: 0.4244\n",
      "Epoch [4/6], Step [3500/6750], Loss: 0.2224\n",
      "Epoch [4/6], Step [3600/6750], Loss: 0.2980\n",
      "Epoch [4/6], Step [3700/6750], Loss: 0.3594\n",
      "Epoch [4/6], Step [3800/6750], Loss: 0.2786\n",
      "Epoch [4/6], Step [3900/6750], Loss: 0.2197\n",
      "Epoch [4/6], Step [4000/6750], Loss: 0.2915\n",
      "Epoch [4/6], Step [4100/6750], Loss: 0.2507\n",
      "Epoch [4/6], Step [4200/6750], Loss: 0.3204\n",
      "Epoch [4/6], Step [4300/6750], Loss: 0.2221\n",
      "Epoch [4/6], Step [4400/6750], Loss: 0.2753\n",
      "Epoch [4/6], Step [4500/6750], Loss: 0.2442\n",
      "Epoch [4/6], Step [4600/6750], Loss: 0.2738\n",
      "Epoch [4/6], Step [4700/6750], Loss: 0.2334\n",
      "Epoch [4/6], Step [4800/6750], Loss: 0.3103\n",
      "Epoch [4/6], Step [4900/6750], Loss: 0.1717\n",
      "Epoch [4/6], Step [5000/6750], Loss: 0.2450\n",
      "Epoch [4/6], Step [5100/6750], Loss: 0.2407\n",
      "Epoch [4/6], Step [5200/6750], Loss: 0.3325\n",
      "Epoch [4/6], Step [5300/6750], Loss: 0.3043\n",
      "Epoch [4/6], Step [5400/6750], Loss: 0.2769\n",
      "Epoch [4/6], Step [5500/6750], Loss: 0.2965\n",
      "Epoch [4/6], Step [5600/6750], Loss: 0.2978\n",
      "Epoch [4/6], Step [5700/6750], Loss: 0.3463\n",
      "Epoch [4/6], Step [5800/6750], Loss: 0.2136\n",
      "Epoch [4/6], Step [5900/6750], Loss: 0.2518\n",
      "Epoch [4/6], Step [6000/6750], Loss: 0.4207\n",
      "Epoch [4/6], Step [6100/6750], Loss: 0.2378\n",
      "Epoch [4/6], Step [6200/6750], Loss: 0.2093\n",
      "Epoch [4/6], Step [6300/6750], Loss: 0.2314\n",
      "Epoch [4/6], Step [6400/6750], Loss: 0.2982\n",
      "Epoch [4/6], Step [6500/6750], Loss: 0.2251\n",
      "Epoch [4/6], Step [6600/6750], Loss: 0.4104\n",
      "Epoch [4/6], Step [6700/6750], Loss: 0.2622\n",
      "Epoch [5/6], Step [100/6750], Loss: 0.4288\n",
      "Epoch [5/6], Step [200/6750], Loss: 0.2260\n",
      "Epoch [5/6], Step [300/6750], Loss: 0.2389\n",
      "Epoch [5/6], Step [400/6750], Loss: 0.2624\n",
      "Epoch [5/6], Step [500/6750], Loss: 0.1975\n",
      "Epoch [5/6], Step [600/6750], Loss: 0.2521\n",
      "Epoch [5/6], Step [700/6750], Loss: 0.2272\n",
      "Epoch [5/6], Step [800/6750], Loss: 0.3664\n",
      "Epoch [5/6], Step [900/6750], Loss: 0.3051\n",
      "Epoch [5/6], Step [1000/6750], Loss: 0.2739\n",
      "Epoch [5/6], Step [1100/6750], Loss: 0.2772\n",
      "Epoch [5/6], Step [1200/6750], Loss: 0.2299\n",
      "Epoch [5/6], Step [1300/6750], Loss: 0.1946\n",
      "Epoch [5/6], Step [1400/6750], Loss: 0.2229\n",
      "Epoch [5/6], Step [1500/6750], Loss: 0.3290\n",
      "Epoch [5/6], Step [1600/6750], Loss: 0.2596\n",
      "Epoch [5/6], Step [1700/6750], Loss: 0.1822\n",
      "Epoch [5/6], Step [1800/6750], Loss: 0.2698\n",
      "Epoch [5/6], Step [1900/6750], Loss: 0.2923\n",
      "Epoch [5/6], Step [2000/6750], Loss: 0.2532\n",
      "Epoch [5/6], Step [2100/6750], Loss: 0.2948\n",
      "Epoch [5/6], Step [2200/6750], Loss: 0.2558\n",
      "Epoch [5/6], Step [2300/6750], Loss: 0.2198\n",
      "Epoch [5/6], Step [2400/6750], Loss: 0.2256\n",
      "Epoch [5/6], Step [2500/6750], Loss: 0.3949\n",
      "Epoch [5/6], Step [2600/6750], Loss: 0.2873\n",
      "Epoch [5/6], Step [2700/6750], Loss: 0.3919\n",
      "Epoch [5/6], Step [2800/6750], Loss: 0.1756\n",
      "Epoch [5/6], Step [2900/6750], Loss: 0.3655\n",
      "Epoch [5/6], Step [3000/6750], Loss: 0.3083\n",
      "Epoch [5/6], Step [3100/6750], Loss: 0.2394\n",
      "Epoch [5/6], Step [3200/6750], Loss: 0.4360\n",
      "Epoch [5/6], Step [3300/6750], Loss: 0.2443\n",
      "Epoch [5/6], Step [3400/6750], Loss: 0.3129\n",
      "Epoch [5/6], Step [3500/6750], Loss: 0.3012\n",
      "Epoch [5/6], Step [3600/6750], Loss: 0.2452\n",
      "Epoch [5/6], Step [3700/6750], Loss: 0.2287\n",
      "Epoch [5/6], Step [3800/6750], Loss: 0.3136\n",
      "Epoch [5/6], Step [3900/6750], Loss: 0.2186\n",
      "Epoch [5/6], Step [4000/6750], Loss: 0.3242\n",
      "Epoch [5/6], Step [4100/6750], Loss: 0.2364\n",
      "Epoch [5/6], Step [4200/6750], Loss: 0.2600\n",
      "Epoch [5/6], Step [4300/6750], Loss: 0.2077\n",
      "Epoch [5/6], Step [4400/6750], Loss: 0.2091\n",
      "Epoch [5/6], Step [4500/6750], Loss: 0.2048\n",
      "Epoch [5/6], Step [4600/6750], Loss: 0.1800\n",
      "Epoch [5/6], Step [4700/6750], Loss: 0.3001\n",
      "Epoch [5/6], Step [4800/6750], Loss: 0.2349\n",
      "Epoch [5/6], Step [4900/6750], Loss: 0.2651\n",
      "Epoch [5/6], Step [5000/6750], Loss: 0.2850\n",
      "Epoch [5/6], Step [5100/6750], Loss: 0.3020\n",
      "Epoch [5/6], Step [5200/6750], Loss: 0.4214\n",
      "Epoch [5/6], Step [5300/6750], Loss: 0.3707\n",
      "Epoch [5/6], Step [5400/6750], Loss: 0.2863\n",
      "Epoch [5/6], Step [5500/6750], Loss: 0.2435\n",
      "Epoch [5/6], Step [5600/6750], Loss: 0.2697\n",
      "Epoch [5/6], Step [5700/6750], Loss: 0.2157\n",
      "Epoch [5/6], Step [5800/6750], Loss: 0.3022\n",
      "Epoch [5/6], Step [5900/6750], Loss: 0.2327\n",
      "Epoch [5/6], Step [6000/6750], Loss: 0.2276\n",
      "Epoch [5/6], Step [6100/6750], Loss: 0.2839\n",
      "Epoch [5/6], Step [6200/6750], Loss: 0.3112\n",
      "Epoch [5/6], Step [6300/6750], Loss: 0.2373\n",
      "Epoch [5/6], Step [6400/6750], Loss: 0.2458\n",
      "Epoch [5/6], Step [6500/6750], Loss: 0.2243\n",
      "Epoch [5/6], Step [6600/6750], Loss: 0.2009\n",
      "Epoch [5/6], Step [6700/6750], Loss: 0.2048\n",
      "Epoch [6/6], Step [100/6750], Loss: 0.2806\n",
      "Epoch [6/6], Step [200/6750], Loss: 0.2510\n",
      "Epoch [6/6], Step [300/6750], Loss: 0.3108\n",
      "Epoch [6/6], Step [400/6750], Loss: 0.2919\n",
      "Epoch [6/6], Step [500/6750], Loss: 0.2209\n",
      "Epoch [6/6], Step [600/6750], Loss: 0.1912\n",
      "Epoch [6/6], Step [700/6750], Loss: 0.2521\n",
      "Epoch [6/6], Step [800/6750], Loss: 0.2538\n",
      "Epoch [6/6], Step [900/6750], Loss: 0.2022\n",
      "Epoch [6/6], Step [1000/6750], Loss: 0.2811\n",
      "Epoch [6/6], Step [1100/6750], Loss: 0.2903\n",
      "Epoch [6/6], Step [1200/6750], Loss: 0.2441\n",
      "Epoch [6/6], Step [1300/6750], Loss: 0.2853\n",
      "Epoch [6/6], Step [1400/6750], Loss: 0.3267\n",
      "Epoch [6/6], Step [1500/6750], Loss: 0.3007\n",
      "Epoch [6/6], Step [1600/6750], Loss: 0.2742\n",
      "Epoch [6/6], Step [1700/6750], Loss: 0.2613\n",
      "Epoch [6/6], Step [1800/6750], Loss: 0.2431\n",
      "Epoch [6/6], Step [1900/6750], Loss: 0.3320\n",
      "Epoch [6/6], Step [2000/6750], Loss: 0.3030\n",
      "Epoch [6/6], Step [2100/6750], Loss: 0.3214\n",
      "Epoch [6/6], Step [2200/6750], Loss: 0.2768\n",
      "Epoch [6/6], Step [2300/6750], Loss: 0.2058\n",
      "Epoch [6/6], Step [2400/6750], Loss: 0.3662\n",
      "Epoch [6/6], Step [2500/6750], Loss: 0.2268\n",
      "Epoch [6/6], Step [2600/6750], Loss: 0.3194\n",
      "Epoch [6/6], Step [2700/6750], Loss: 0.2308\n",
      "Epoch [6/6], Step [2800/6750], Loss: 0.2963\n",
      "Epoch [6/6], Step [2900/6750], Loss: 0.3163\n",
      "Epoch [6/6], Step [3000/6750], Loss: 0.3005\n",
      "Epoch [6/6], Step [3100/6750], Loss: 0.3517\n",
      "Epoch [6/6], Step [3200/6750], Loss: 0.2144\n",
      "Epoch [6/6], Step [3300/6750], Loss: 0.1985\n",
      "Epoch [6/6], Step [3400/6750], Loss: 0.2833\n",
      "Epoch [6/6], Step [3500/6750], Loss: 0.2938\n",
      "Epoch [6/6], Step [3600/6750], Loss: 0.1800\n",
      "Epoch [6/6], Step [3700/6750], Loss: 0.3421\n",
      "Epoch [6/6], Step [3800/6750], Loss: 0.3273\n",
      "Epoch [6/6], Step [3900/6750], Loss: 0.2526\n",
      "Epoch [6/6], Step [4000/6750], Loss: 0.2705\n",
      "Epoch [6/6], Step [4100/6750], Loss: 0.2230\n",
      "Epoch [6/6], Step [4200/6750], Loss: 0.3775\n",
      "Epoch [6/6], Step [4300/6750], Loss: 0.2365\n",
      "Epoch [6/6], Step [4400/6750], Loss: 0.2677\n",
      "Epoch [6/6], Step [4500/6750], Loss: 0.4365\n",
      "Epoch [6/6], Step [4600/6750], Loss: 0.2050\n",
      "Epoch [6/6], Step [4700/6750], Loss: 0.2662\n",
      "Epoch [6/6], Step [4800/6750], Loss: 0.2705\n",
      "Epoch [6/6], Step [4900/6750], Loss: 0.2501\n",
      "Epoch [6/6], Step [5000/6750], Loss: 0.2490\n",
      "Epoch [6/6], Step [5100/6750], Loss: 0.2140\n",
      "Epoch [6/6], Step [5200/6750], Loss: 0.3434\n",
      "Epoch [6/6], Step [5300/6750], Loss: 0.2905\n",
      "Epoch [6/6], Step [5400/6750], Loss: 0.2471\n",
      "Epoch [6/6], Step [5500/6750], Loss: 0.3875\n",
      "Epoch [6/6], Step [5600/6750], Loss: 0.3602\n",
      "Epoch [6/6], Step [5700/6750], Loss: 0.2166\n",
      "Epoch [6/6], Step [5800/6750], Loss: 0.2698\n",
      "Epoch [6/6], Step [5900/6750], Loss: 0.1831\n",
      "Epoch [6/6], Step [6000/6750], Loss: 0.2882\n",
      "Epoch [6/6], Step [6100/6750], Loss: 0.1987\n",
      "Epoch [6/6], Step [6200/6750], Loss: 0.3679\n",
      "Epoch [6/6], Step [6300/6750], Loss: 0.3132\n",
      "Epoch [6/6], Step [6400/6750], Loss: 0.3358\n",
      "Epoch [6/6], Step [6500/6750], Loss: 0.1964\n",
      "Epoch [6/6], Step [6600/6750], Loss: 0.3031\n",
      "Epoch [6/6], Step [6700/6750], Loss: 0.3385\n",
      "Model saved to C:/Users/rosti/Desktop/model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(images, titles=None, cmap=None):\n",
    "    \"\"\" Показывает серию изображений. \"\"\"\n",
    "    n = len(images)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(15, 5))\n",
    "    if n == 1:\n",
    "        axs = [axs]\n",
    "    for i, image in enumerate(images):\n",
    "        axs[i].imshow(image.squeeze(), cmap=cmap)\n",
    "        axs[i].axis('off')\n",
    "        if titles is not None:\n",
    "            axs[i].set_title(titles[i])\n",
    "    plt.show()\n",
    "    \n",
    "class ImageToImageDataset(Dataset):\n",
    "    def __init__(self, input_dir, target_dir=None, transform=None, target_transform=None, mode='train'):\n",
    "        self.input_dir = input_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform or transform\n",
    "        self.mode = mode\n",
    "        self.filenames = [f for f in os.listdir(input_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path = os.path.join(self.input_dir, self.filenames[idx])\n",
    "        input_image = Image.open(input_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            input_image = self.transform(input_image)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            target_path = os.path.join(self.target_dir, self.filenames[idx])\n",
    "            target_image = Image.open(target_path).convert('L')\n",
    "\n",
    "            if self.target_transform:\n",
    "                target_image = self.target_transform(target_image)\n",
    "\n",
    "            return input_image, target_image\n",
    "        else:\n",
    "            return input_image\n",
    "\n",
    "import torchvision\n",
    "\n",
    "def save_image(tensor, filename):\n",
    "    \"\"\" Сохраняет тензор как изображение. \"\"\"\n",
    "    torchvision.utils.save_image(tensor, filename)\n",
    "    \n",
    "# Определение модели\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 1, 3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.sigmoid(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "# Параметры\n",
    "num_epochs = 6\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Подготовка данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Нормализация если нужна\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Только преобразование в тензор для масок\n",
    "])\n",
    "\n",
    "train_dataset = ImageToImageDataset(input_dir=\"C:/Users/rosti/Desktop/data/train_images\", target_dir=\"C:/Users/rosti/Desktop/data/train_lung_masks\", transform=transform, target_transform =target_transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = SimpleCNN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Обучение модели\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Визуализация\n",
    "        \n",
    "\n",
    "        # Печать статистики обучения\n",
    "        if (i+1) % 100 == 0:\n",
    "        #     num_images_to_show = 1\n",
    "        #     for j in range(num_images_to_show):\n",
    "        #         save_image(inputs[j], f'output/epoch_{epoch}_{i+1}_input_{j}.png')\n",
    "        #         save_image(outputs[j], f'output/epoch_{epoch}_{i+1}_output_{j}.png')\n",
    "        #         save_image(labels[j], f'output/epoch_{epoch}_{i+1}_label_{j}.png')\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "model_path = \"C:/Users/rosti/Desktop/model.pth\"  # Укажите желаемый путь для сохранения модели\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098437a-0593-4368-9191-91c27aecf5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
