{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:05.420721Z",
     "start_time": "2023-12-07T20:51:05.417810Z"
    }
   },
   "id": "70c1aed05d7dbf71"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:05.445633Z",
     "start_time": "2023-12-07T20:51:05.424323Z"
    }
   },
   "outputs": [],
   "source": [
    "from support_module import ImageToNumDataset, NoMaskModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:05.447680Z",
     "start_time": "2023-12-07T20:51:05.436658Z"
    }
   },
   "id": "b2acdf1950fed443"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms.v2 import ToDtype, Normalize, Compose, PILToTensor\n",
    "\n",
    "transform = Compose([\n",
    "    PILToTensor(),\n",
    "    ToDtype(torch.float32, scale=True),\n",
    "    Normalize((0.5,), (0.5,))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:05.464228Z",
     "start_time": "2023-12-07T20:51:05.455044Z"
    }
   },
   "id": "92567a6e2f7c9ed"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "dataset = ImageToNumDataset(\"data/train_images\", answers_file=\"data/train_answers.csv\", transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:05.597661Z",
     "start_time": "2023-12-07T20:51:05.479968Z"
    }
   },
   "id": "4c0d528f745d5416"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "train_dataset, validation_dataset = random_split(dataset, (0.8, 0.2))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=56, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=56, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:05.615326Z",
     "start_time": "2023-12-07T20:51:05.596143Z"
    }
   },
   "id": "6ff78bcecf5d1461"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "model = NoMaskModel()\n",
    "model = model.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:06.791550Z",
     "start_time": "2023-12-07T20:51:05.617971Z"
    }
   },
   "id": "6a7ad10130281076"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:06.807297Z",
     "start_time": "2023-12-07T20:51:06.804224Z"
    }
   },
   "id": "56276a7277848d65"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:06.808031Z",
     "start_time": "2023-12-07T20:51:06.806276Z"
    }
   },
   "id": "ba2a87d5be33d952"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.engine import create_supervised_trainer, create_supervised_evaluator\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=DEVICE)\n",
    "evaluator = create_supervised_evaluator(model, metrics={'accuracy': Accuracy(), 'nll': Loss(criterion)}, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:06.830435Z",
     "start_time": "2023-12-07T20:51:06.807951Z"
    }
   },
   "id": "124ae499ac32c1cc"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Сбор потерь и метрик для построения графиков\n",
    "train_loss_values = []\n",
    "validation_loss_values = []\n",
    "validation_accuracy_values = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:06.831089Z",
     "start_time": "2023-12-07T20:51:06.818301Z"
    }
   },
   "id": "cdb25116c5ca23a1"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:06.831984Z",
     "start_time": "2023-12-07T20:51:06.823170Z"
    }
   },
   "id": "a5f6d77d640e91a1"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "EPOCHS = 25"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:06.832761Z",
     "start_time": "2023-12-07T20:51:06.830114Z"
    }
   },
   "id": "9d42f86d6a268bd9"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from ignite.engine import Events\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    # Запуск оценки модели на обучающем наборе данных\n",
    "    evaluator.run(train_dataloader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    # Сбор и вывод средней точности и потерь на обучающем наборе\n",
    "    train_loss_values.append(metrics['nll'])\n",
    "    logging.info(\n",
    "        f\"Training Results - Epoch: {engine.state.epoch}  \"\n",
    "        f\"Avg accuracy: {metrics['accuracy']:.2f} \"\n",
    "        f\"Avg loss: {metrics['nll']:.2f}\"\n",
    "    )\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    logging.info(f\"Starting validation on epoch {engine.state.epoch}\")\n",
    "    # Запуск оценки модели на валидационном наборе данных\n",
    "    evaluator.run(validation_dataloader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    # Сбор и вывод средней точности и потерь на валидационном наборе\n",
    "    validation_loss_values.append(metrics['nll'])\n",
    "    validation_accuracy_values.append(metrics['accuracy'])\n",
    "    logging.info(\n",
    "        f\"Validation Results - Epoch: {engine.state.epoch}  \"\n",
    "        f\"Avg accuracy: {metrics['accuracy']:.3f} \"\n",
    "        f\"Avg loss: {metrics['nll']:.3f}\"\n",
    "    )\n",
    "    logging.info(f\"End of validation on epoch {engine.state.epoch}\")\n",
    "    torch.save(model.state_dict(), \"models/model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:06.840531Z",
     "start_time": "2023-12-07T20:51:06.835602Z"
    }
   },
   "id": "84b5ce8888cd671a"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=25.\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:898\u001B[0m, in \u001B[0;36mEngine.run\u001B[0;34m(self, data, max_epochs, epoch_length, seed)\u001B[0m\n\u001B[1;32m    895\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mdataloader \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m    897\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minterrupt_resume_enabled:\n\u001B[0;32m--> 898\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_internal_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    899\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    900\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_legacy()\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:941\u001B[0m, in \u001B[0;36mEngine._internal_run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    939\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_generator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_as_gen()\n\u001B[1;32m    940\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 941\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_internal_run_generator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    942\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m out:\n\u001B[1;32m    943\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_generator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:999\u001B[0m, in \u001B[0;36mEngine._internal_run_as_gen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    997\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    998\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEngine run is terminating due to exception: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 999\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_exception\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1001\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1002\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:644\u001B[0m, in \u001B[0;36mEngine._handle_exception\u001B[0;34m(self, e)\u001B[0m\n\u001B[1;32m    642\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mEXCEPTION_RAISED, e)\n\u001B[1;32m    643\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 644\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:965\u001B[0m, in \u001B[0;36mEngine._internal_run_as_gen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    962\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    963\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setup_engine()\n\u001B[0;32m--> 965\u001B[0m epoch_time_taken \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_once_on_dataset_as_gen()\n\u001B[1;32m    967\u001B[0m \u001B[38;5;66;03m# time is available for handlers but must be updated after fire\u001B[39;00m\n\u001B[1;32m    968\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mtimes[Events\u001B[38;5;241m.\u001B[39mEPOCH_COMPLETED\u001B[38;5;241m.\u001B[39mname] \u001B[38;5;241m=\u001B[39m epoch_time_taken\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/engine.py:1074\u001B[0m, in \u001B[0;36mEngine._run_once_on_dataset_as_gen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mITERATION_STARTED)\n\u001B[1;32m   1072\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_terminate_or_interrupt()\n\u001B[0;32m-> 1074\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mITERATION_COMPLETED)\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_terminate_or_interrupt()\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/ignite/engine/__init__.py:117\u001B[0m, in \u001B[0;36msupervised_training_step.<locals>.update\u001B[0;34m(engine, batch)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gradient_accumulation_steps \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    116\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss \u001B[38;5;241m/\u001B[39m gradient_accumulation_steps\n\u001B[0;32m--> 117\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m engine\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39miteration \u001B[38;5;241m%\u001B[39m gradient_accumulation_steps \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    119\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/DataspellProjects/ML-intensive-Yandex-Academy-autumn-2023/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run(train_dataloader, max_epochs=EPOCHS, epoch_length=20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:09.698186Z",
     "start_time": "2023-12-07T20:51:06.838554Z"
    }
   },
   "id": "232d9cbfec3d0e69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:09.698840Z",
     "start_time": "2023-12-07T20:51:09.698706Z"
    }
   },
   "id": "3adf72d08684ec5b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Графики обучения\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_values, label='Training Loss')\n",
    "plt.plot(validation_loss_values, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(validation_accuracy_values, label='Validation Accuracy', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:09.700760Z",
     "start_time": "2023-12-07T20:51:09.699446Z"
    }
   },
   "id": "cb1d0dbd6d4735aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "# Смотрим результат обучения\n",
    "for i in range(20):\n",
    "    x, y_true = validation_dataset[i]\n",
    "    y_pred = torch.argmax(model(transform(x.to(DEVICE))))\n",
    "    plt.subplot(2, 10, i + 1)\n",
    "    plt.imshow(x.permute(1, 2, 0) * 0.25 + 0.5)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    class_to_idx = {value: key for key, value in validation_dataset.class_to_idx.items()}\n",
    "    plt.title(f'True = {class_to_idx[y_true]}\\nPred = {class_to_idx[y_pred.item()]}')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-07T20:51:09.700522Z"
    }
   },
   "id": "5123afea665da494"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "test_model = NoMaskModel()\n",
    "test_model = test_model.to(DEVICE)\n",
    "test_model.load_state_dict(torch.load(\"models/model.pt\"))\n",
    "test_dataset = ImageToNumDataset(\"data/test_images\", transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T20:51:18.960347Z",
     "start_time": "2023-12-07T20:51:16.822551Z"
    }
   },
   "id": "f336c2cc32c851fe"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "0.13%\n",
      "0.14%\n",
      "0.27%\n",
      "0.29%\n",
      "0.42%\n",
      "0.43%\n",
      "0.56%\n",
      "0.58%\n",
      "0.71%\n",
      "0.72%\n",
      "0.85%\n",
      "0.87%\n",
      "1.00%\n",
      "1.01%\n",
      "1.14%\n",
      "1.16%\n",
      "1.29%\n",
      "1.30%\n",
      "1.43%\n",
      "1.45%\n",
      "1.58%\n",
      "1.59%\n",
      "1.72%\n",
      "1.73%\n",
      "1.86%\n",
      "1.88%\n",
      "2.01%\n",
      "2.02%\n",
      "2.15%\n",
      "2.17%\n",
      "2.30%\n",
      "2.31%\n",
      "2.44%\n",
      "2.46%\n",
      "2.59%\n",
      "2.60%\n",
      "2.73%\n",
      "2.75%\n",
      "2.88%\n",
      "2.89%\n",
      "3.02%\n",
      "3.03%\n",
      "3.16%\n",
      "3.18%\n",
      "3.31%\n",
      "3.32%\n",
      "3.45%\n",
      "3.47%\n",
      "3.60%\n",
      "3.61%\n",
      "3.74%\n",
      "3.76%\n",
      "3.89%\n",
      "3.90%\n",
      "4.03%\n",
      "4.05%\n",
      "4.18%\n",
      "4.19%\n",
      "4.32%\n",
      "4.34%\n",
      "4.47%\n",
      "4.48%\n",
      "4.61%\n",
      "4.62%\n",
      "4.75%\n",
      "4.77%\n",
      "4.90%\n",
      "4.91%\n",
      "5.04%\n",
      "5.06%\n",
      "5.19%\n",
      "5.20%\n",
      "5.33%\n",
      "5.35%\n",
      "5.48%\n",
      "5.49%\n",
      "5.62%\n",
      "5.64%\n",
      "5.77%\n",
      "5.78%\n",
      "5.91%\n",
      "5.92%\n",
      "6.05%\n",
      "6.07%\n",
      "6.20%\n",
      "6.21%\n",
      "6.34%\n",
      "6.36%\n",
      "6.49%\n",
      "6.50%\n",
      "6.63%\n",
      "6.65%\n",
      "6.78%\n",
      "6.79%\n",
      "6.92%\n",
      "6.94%\n",
      "7.07%\n",
      "7.08%\n",
      "7.21%\n",
      "7.23%\n",
      "7.36%\n",
      "7.37%\n",
      "7.50%\n",
      "7.51%\n",
      "7.64%\n",
      "7.66%\n",
      "7.79%\n",
      "7.80%\n",
      "7.93%\n",
      "7.95%\n",
      "8.08%\n",
      "8.09%\n",
      "8.22%\n",
      "8.24%\n",
      "8.37%\n",
      "8.38%\n",
      "8.51%\n",
      "8.53%\n",
      "8.66%\n",
      "8.67%\n",
      "8.80%\n",
      "8.82%\n",
      "8.95%\n",
      "8.96%\n",
      "9.09%\n",
      "9.10%\n",
      "9.23%\n",
      "9.25%\n",
      "9.38%\n",
      "9.39%\n",
      "9.52%\n",
      "9.54%\n",
      "9.67%\n",
      "9.68%\n",
      "9.81%\n",
      "9.83%\n",
      "9.96%\n",
      "9.97%\n",
      "10.10%\n",
      "10.12%\n",
      "10.25%\n",
      "10.26%\n",
      "10.39%\n",
      "10.40%\n",
      "10.53%\n",
      "10.55%\n",
      "10.68%\n",
      "10.69%\n",
      "10.82%\n",
      "10.84%\n",
      "10.97%\n",
      "10.98%\n",
      "11.11%\n",
      "11.13%\n",
      "11.26%\n",
      "11.27%\n",
      "11.40%\n",
      "11.42%\n",
      "11.55%\n",
      "11.56%\n",
      "11.69%\n",
      "11.71%\n",
      "11.84%\n",
      "11.85%\n",
      "11.98%\n",
      "11.99%\n",
      "12.12%\n",
      "12.14%\n",
      "12.27%\n",
      "12.28%\n",
      "12.41%\n",
      "12.43%\n",
      "12.56%\n",
      "12.57%\n",
      "12.70%\n",
      "12.72%\n",
      "12.85%\n",
      "12.86%\n",
      "12.99%\n",
      "13.01%\n",
      "13.14%\n",
      "13.15%\n",
      "13.28%\n",
      "13.29%\n",
      "13.42%\n",
      "13.44%\n",
      "13.57%\n",
      "13.58%\n",
      "13.71%\n",
      "13.73%\n",
      "13.86%\n",
      "13.87%\n",
      "14.00%\n",
      "14.02%\n",
      "14.15%\n",
      "14.16%\n",
      "14.29%\n",
      "14.31%\n",
      "14.44%\n",
      "14.45%\n",
      "14.58%\n",
      "14.60%\n",
      "14.73%\n",
      "14.74%\n",
      "14.87%\n",
      "14.88%\n",
      "15.01%\n",
      "15.03%\n",
      "15.16%\n",
      "15.17%\n",
      "15.30%\n",
      "15.32%\n",
      "15.45%\n",
      "15.46%\n",
      "15.59%\n",
      "15.61%\n",
      "15.74%\n",
      "15.75%\n",
      "15.88%\n",
      "15.90%\n",
      "16.03%\n",
      "16.04%\n",
      "16.17%\n",
      "16.18%\n",
      "16.32%\n",
      "16.33%\n",
      "16.46%\n",
      "16.47%\n",
      "16.60%\n",
      "16.62%\n",
      "16.75%\n",
      "16.76%\n",
      "16.89%\n",
      "16.91%\n",
      "17.04%\n",
      "17.05%\n",
      "17.18%\n",
      "17.20%\n",
      "17.33%\n",
      "17.34%\n",
      "17.47%\n",
      "17.49%\n",
      "17.62%\n",
      "17.63%\n",
      "17.76%\n",
      "17.77%\n",
      "17.90%\n",
      "17.92%\n",
      "18.05%\n",
      "18.06%\n",
      "18.19%\n",
      "18.21%\n",
      "18.34%\n",
      "18.35%\n",
      "18.48%\n",
      "18.50%\n",
      "18.63%\n",
      "18.64%\n",
      "18.77%\n",
      "18.79%\n",
      "18.92%\n",
      "18.93%\n",
      "19.06%\n",
      "19.08%\n",
      "19.21%\n",
      "19.22%\n",
      "19.35%\n",
      "19.36%\n",
      "19.49%\n",
      "19.51%\n",
      "19.64%\n",
      "19.65%\n",
      "19.78%\n",
      "19.80%\n",
      "19.93%\n",
      "19.94%\n",
      "20.07%\n",
      "20.09%\n",
      "20.22%\n",
      "20.23%\n",
      "20.36%\n",
      "20.38%\n",
      "20.51%\n",
      "20.52%\n",
      "20.65%\n",
      "20.66%\n",
      "20.79%\n",
      "20.81%\n",
      "20.94%\n",
      "20.95%\n",
      "21.08%\n",
      "21.10%\n",
      "21.23%\n",
      "21.24%\n",
      "21.37%\n",
      "21.39%\n",
      "21.52%\n",
      "21.53%\n",
      "21.66%\n",
      "21.68%\n",
      "21.81%\n",
      "21.82%\n",
      "21.95%\n",
      "21.97%\n",
      "22.10%\n",
      "22.11%\n",
      "22.24%\n",
      "22.25%\n",
      "22.38%\n",
      "22.40%\n",
      "22.53%\n",
      "22.54%\n",
      "22.67%\n",
      "22.69%\n",
      "22.82%\n",
      "22.83%\n",
      "22.96%\n",
      "22.98%\n",
      "23.11%\n",
      "23.12%\n",
      "23.25%\n",
      "23.27%\n",
      "23.40%\n",
      "23.41%\n",
      "23.54%\n",
      "23.55%\n",
      "23.68%\n",
      "23.70%\n",
      "23.83%\n",
      "23.84%\n",
      "23.97%\n",
      "23.99%\n",
      "24.12%\n",
      "24.13%\n",
      "24.26%\n",
      "24.28%\n",
      "24.41%\n",
      "24.42%\n",
      "24.55%\n",
      "24.57%\n",
      "24.70%\n",
      "24.71%\n",
      "24.84%\n",
      "24.86%\n",
      "24.99%\n",
      "25.00%\n",
      "25.13%\n",
      "25.14%\n",
      "25.27%\n",
      "25.29%\n",
      "25.42%\n",
      "25.43%\n",
      "25.56%\n",
      "25.58%\n",
      "25.71%\n",
      "25.72%\n",
      "25.85%\n",
      "25.87%\n",
      "26.00%\n",
      "26.01%\n",
      "26.14%\n",
      "26.16%\n",
      "26.29%\n",
      "26.30%\n",
      "26.43%\n",
      "26.45%\n",
      "26.58%\n",
      "26.59%\n",
      "26.72%\n",
      "26.73%\n",
      "26.86%\n",
      "26.88%\n",
      "27.01%\n",
      "27.02%\n",
      "27.15%\n",
      "27.17%\n",
      "27.30%\n",
      "27.31%\n",
      "27.44%\n",
      "27.46%\n",
      "27.59%\n",
      "27.60%\n",
      "27.73%\n",
      "27.75%\n",
      "27.88%\n",
      "27.89%\n",
      "28.02%\n",
      "28.03%\n",
      "28.16%\n",
      "28.18%\n",
      "28.31%\n",
      "28.32%\n",
      "28.45%\n",
      "28.47%\n",
      "28.60%\n",
      "28.61%\n",
      "28.74%\n",
      "28.76%\n",
      "28.89%\n",
      "28.90%\n",
      "29.03%\n",
      "29.05%\n",
      "29.18%\n",
      "29.19%\n",
      "29.32%\n",
      "29.34%\n",
      "29.47%\n",
      "29.48%\n",
      "29.61%\n",
      "29.62%\n",
      "29.75%\n",
      "29.77%\n",
      "29.90%\n",
      "29.91%\n",
      "30.04%\n",
      "30.06%\n",
      "30.19%\n",
      "30.20%\n",
      "30.33%\n",
      "30.35%\n",
      "30.48%\n",
      "30.49%\n",
      "30.62%\n",
      "30.64%\n",
      "30.77%\n",
      "30.78%\n",
      "30.91%\n",
      "30.92%\n",
      "31.05%\n",
      "31.07%\n",
      "31.20%\n",
      "31.21%\n",
      "31.34%\n",
      "31.36%\n",
      "31.49%\n",
      "31.50%\n",
      "31.63%\n",
      "31.65%\n",
      "31.78%\n",
      "31.79%\n",
      "31.92%\n",
      "31.94%\n",
      "32.07%\n",
      "32.08%\n",
      "32.21%\n",
      "32.23%\n",
      "32.36%\n",
      "32.37%\n",
      "32.50%\n",
      "32.51%\n",
      "32.64%\n",
      "32.66%\n",
      "32.79%\n",
      "32.80%\n",
      "32.93%\n",
      "32.95%\n",
      "33.08%\n",
      "33.09%\n",
      "33.22%\n",
      "33.24%\n",
      "33.37%\n",
      "33.38%\n",
      "33.51%\n",
      "33.53%\n",
      "33.66%\n",
      "33.67%\n",
      "33.80%\n",
      "33.82%\n",
      "33.95%\n",
      "33.96%\n",
      "34.09%\n",
      "34.10%\n",
      "34.23%\n",
      "34.25%\n",
      "34.38%\n",
      "34.39%\n",
      "34.52%\n",
      "34.54%\n",
      "34.67%\n",
      "34.68%\n",
      "34.81%\n",
      "34.83%\n",
      "34.96%\n",
      "34.97%\n",
      "35.10%\n",
      "35.12%\n",
      "35.25%\n",
      "35.26%\n",
      "35.39%\n",
      "35.40%\n",
      "35.53%\n",
      "35.55%\n",
      "35.68%\n",
      "35.69%\n",
      "35.82%\n",
      "35.84%\n",
      "35.97%\n",
      "35.98%\n",
      "36.11%\n",
      "36.13%\n",
      "36.26%\n",
      "36.27%\n",
      "36.40%\n",
      "36.42%\n",
      "36.55%\n",
      "36.56%\n",
      "36.69%\n",
      "36.71%\n",
      "36.84%\n",
      "36.85%\n",
      "36.98%\n",
      "36.99%\n",
      "37.12%\n",
      "37.14%\n",
      "37.27%\n",
      "37.28%\n",
      "37.41%\n",
      "37.43%\n",
      "37.56%\n",
      "37.57%\n",
      "37.70%\n",
      "37.72%\n",
      "37.85%\n",
      "37.86%\n",
      "37.99%\n",
      "38.01%\n",
      "38.14%\n",
      "38.15%\n",
      "38.28%\n",
      "38.29%\n",
      "38.42%\n",
      "38.44%\n",
      "38.57%\n",
      "38.58%\n",
      "38.71%\n",
      "38.73%\n",
      "38.86%\n",
      "38.87%\n",
      "39.00%\n",
      "39.02%\n",
      "39.15%\n",
      "39.16%\n",
      "39.29%\n",
      "39.31%\n",
      "39.44%\n",
      "39.45%\n",
      "39.58%\n",
      "39.60%\n",
      "39.73%\n",
      "39.74%\n",
      "39.87%\n",
      "39.88%\n",
      "40.01%\n",
      "40.03%\n",
      "40.16%\n",
      "40.17%\n",
      "40.30%\n",
      "40.32%\n",
      "40.45%\n",
      "40.46%\n",
      "40.59%\n",
      "40.61%\n",
      "40.74%\n",
      "40.75%\n",
      "40.88%\n",
      "40.90%\n",
      "41.03%\n",
      "41.04%\n",
      "41.17%\n",
      "41.18%\n",
      "41.32%\n",
      "41.33%\n",
      "41.46%\n",
      "41.47%\n",
      "41.60%\n",
      "41.62%\n",
      "41.75%\n",
      "41.76%\n",
      "41.89%\n",
      "41.91%\n",
      "42.04%\n",
      "42.05%\n",
      "42.18%\n",
      "42.20%\n",
      "42.33%\n",
      "42.34%\n",
      "42.47%\n",
      "42.49%\n",
      "42.62%\n",
      "42.63%\n",
      "42.76%\n",
      "42.77%\n",
      "42.90%\n",
      "42.92%\n",
      "43.05%\n",
      "43.06%\n",
      "43.19%\n",
      "43.21%\n",
      "43.34%\n",
      "43.35%\n",
      "43.48%\n",
      "43.50%\n",
      "43.63%\n",
      "43.64%\n",
      "43.77%\n",
      "43.79%\n",
      "43.92%\n",
      "43.93%\n",
      "44.06%\n",
      "44.08%\n",
      "44.21%\n",
      "44.22%\n",
      "44.35%\n",
      "44.36%\n",
      "44.49%\n",
      "44.51%\n",
      "44.64%\n",
      "44.65%\n",
      "44.78%\n",
      "44.80%\n",
      "44.93%\n",
      "44.94%\n",
      "45.07%\n",
      "45.09%\n",
      "45.22%\n",
      "45.23%\n",
      "45.36%\n",
      "45.38%\n",
      "45.51%\n",
      "45.52%\n",
      "45.65%\n",
      "45.66%\n",
      "45.79%\n",
      "45.81%\n",
      "45.94%\n",
      "45.95%\n",
      "46.08%\n",
      "46.10%\n",
      "46.23%\n",
      "46.24%\n",
      "46.37%\n",
      "46.39%\n",
      "46.52%\n",
      "46.53%\n",
      "46.66%\n",
      "46.68%\n",
      "46.81%\n",
      "46.82%\n",
      "46.95%\n",
      "46.97%\n",
      "47.10%\n",
      "47.11%\n",
      "47.24%\n",
      "47.25%\n",
      "47.38%\n",
      "47.40%\n",
      "47.53%\n",
      "47.54%\n",
      "47.67%\n",
      "47.69%\n",
      "47.82%\n",
      "47.83%\n",
      "47.96%\n",
      "47.98%\n",
      "48.11%\n",
      "48.12%\n",
      "48.25%\n",
      "48.27%\n",
      "48.40%\n",
      "48.41%\n",
      "48.54%\n",
      "48.55%\n",
      "48.68%\n",
      "48.70%\n",
      "48.83%\n",
      "48.84%\n",
      "48.97%\n",
      "48.99%\n",
      "49.12%\n",
      "49.13%\n",
      "49.26%\n",
      "49.28%\n",
      "49.41%\n",
      "49.42%\n",
      "49.55%\n",
      "49.57%\n",
      "49.70%\n",
      "49.71%\n",
      "49.84%\n",
      "49.86%\n",
      "49.99%\n",
      "50.00%\n",
      "50.13%\n",
      "50.14%\n",
      "50.27%\n",
      "50.29%\n",
      "50.42%\n",
      "50.43%\n",
      "50.56%\n",
      "50.58%\n",
      "50.71%\n",
      "50.72%\n",
      "50.85%\n",
      "50.87%\n",
      "51.00%\n",
      "51.01%\n",
      "51.14%\n",
      "51.16%\n",
      "51.29%\n",
      "51.30%\n",
      "51.43%\n",
      "51.45%\n",
      "51.58%\n",
      "51.59%\n",
      "51.72%\n",
      "51.73%\n",
      "51.86%\n",
      "51.88%\n",
      "52.01%\n",
      "52.02%\n",
      "52.15%\n",
      "52.17%\n",
      "52.30%\n",
      "52.31%\n",
      "52.44%\n",
      "52.46%\n",
      "52.59%\n",
      "52.60%\n",
      "52.73%\n",
      "52.75%\n",
      "52.88%\n",
      "52.89%\n",
      "53.02%\n",
      "53.03%\n",
      "53.16%\n",
      "53.18%\n",
      "53.31%\n",
      "53.32%\n",
      "53.45%\n",
      "53.47%\n",
      "53.60%\n",
      "53.61%\n",
      "53.74%\n",
      "53.76%\n",
      "53.89%\n",
      "53.90%\n",
      "54.03%\n",
      "54.05%\n",
      "54.18%\n",
      "54.19%\n",
      "54.32%\n",
      "54.34%\n",
      "54.47%\n",
      "54.48%\n",
      "54.61%\n",
      "54.62%\n",
      "54.75%\n",
      "54.77%\n",
      "54.90%\n",
      "54.91%\n",
      "55.04%\n",
      "55.06%\n",
      "55.19%\n",
      "55.20%\n",
      "55.33%\n",
      "55.35%\n",
      "55.48%\n",
      "55.49%\n",
      "55.62%\n",
      "55.64%\n",
      "55.77%\n",
      "55.78%\n",
      "55.91%\n",
      "55.92%\n",
      "56.05%\n",
      "56.07%\n",
      "56.20%\n",
      "56.21%\n",
      "56.34%\n",
      "56.36%\n",
      "56.49%\n",
      "56.50%\n",
      "56.63%\n",
      "56.65%\n",
      "56.78%\n",
      "56.79%\n",
      "56.92%\n",
      "56.94%\n",
      "57.07%\n",
      "57.08%\n",
      "57.21%\n",
      "57.23%\n",
      "57.36%\n",
      "57.37%\n",
      "57.50%\n",
      "57.51%\n",
      "57.64%\n",
      "57.66%\n",
      "57.79%\n",
      "57.80%\n",
      "57.93%\n",
      "57.95%\n",
      "58.08%\n",
      "58.09%\n",
      "58.22%\n",
      "58.24%\n",
      "58.37%\n",
      "58.38%\n",
      "58.51%\n",
      "58.53%\n",
      "58.66%\n",
      "58.67%\n",
      "58.80%\n",
      "58.82%\n",
      "58.95%\n",
      "58.96%\n",
      "59.09%\n",
      "59.10%\n",
      "59.23%\n",
      "59.25%\n",
      "59.38%\n",
      "59.39%\n",
      "59.52%\n",
      "59.54%\n",
      "59.67%\n",
      "59.68%\n",
      "59.81%\n",
      "59.83%\n",
      "59.96%\n",
      "59.97%\n",
      "60.10%\n",
      "60.12%\n",
      "60.25%\n",
      "60.26%\n",
      "60.39%\n",
      "60.40%\n",
      "60.53%\n",
      "60.55%\n",
      "60.68%\n",
      "60.69%\n",
      "60.82%\n",
      "60.84%\n",
      "60.97%\n",
      "60.98%\n",
      "61.11%\n",
      "61.13%\n",
      "61.26%\n",
      "61.27%\n",
      "61.40%\n",
      "61.42%\n",
      "61.55%\n",
      "61.56%\n",
      "61.69%\n",
      "61.71%\n",
      "61.84%\n",
      "61.85%\n",
      "61.98%\n",
      "61.99%\n",
      "62.12%\n",
      "62.14%\n",
      "62.27%\n",
      "62.28%\n",
      "62.41%\n",
      "62.43%\n",
      "62.56%\n",
      "62.57%\n",
      "62.70%\n",
      "62.72%\n",
      "62.85%\n",
      "62.86%\n",
      "62.99%\n",
      "63.01%\n",
      "63.14%\n",
      "63.15%\n",
      "63.28%\n",
      "63.29%\n",
      "63.42%\n",
      "63.44%\n",
      "63.57%\n",
      "63.58%\n",
      "63.71%\n",
      "63.73%\n",
      "63.86%\n",
      "63.87%\n",
      "64.00%\n",
      "64.02%\n",
      "64.15%\n",
      "64.16%\n",
      "64.29%\n",
      "64.31%\n",
      "64.44%\n",
      "64.45%\n",
      "64.58%\n",
      "64.60%\n",
      "64.73%\n",
      "64.74%\n",
      "64.87%\n",
      "64.88%\n",
      "65.01%\n",
      "65.03%\n",
      "65.16%\n",
      "65.17%\n",
      "65.30%\n",
      "65.32%\n",
      "65.45%\n",
      "65.46%\n",
      "65.59%\n",
      "65.61%\n",
      "65.74%\n",
      "65.75%\n",
      "65.88%\n",
      "65.90%\n",
      "66.03%\n",
      "66.04%\n",
      "66.17%\n",
      "66.18%\n",
      "66.32%\n",
      "66.33%\n",
      "66.46%\n",
      "66.47%\n",
      "66.60%\n",
      "66.62%\n",
      "66.75%\n",
      "66.76%\n",
      "66.89%\n",
      "66.91%\n",
      "67.04%\n",
      "67.05%\n",
      "67.18%\n",
      "67.20%\n",
      "67.33%\n",
      "67.34%\n",
      "67.47%\n",
      "67.49%\n",
      "67.62%\n",
      "67.63%\n",
      "67.76%\n",
      "67.77%\n",
      "67.90%\n",
      "67.92%\n",
      "68.05%\n",
      "68.06%\n",
      "68.19%\n",
      "68.21%\n",
      "68.34%\n",
      "68.35%\n",
      "68.48%\n",
      "68.50%\n",
      "68.63%\n",
      "68.64%\n",
      "68.77%\n",
      "68.79%\n",
      "68.92%\n",
      "68.93%\n",
      "69.06%\n",
      "69.08%\n",
      "69.21%\n",
      "69.22%\n",
      "69.35%\n",
      "69.36%\n",
      "69.49%\n",
      "69.51%\n",
      "69.64%\n",
      "69.65%\n",
      "69.78%\n",
      "69.80%\n",
      "69.93%\n",
      "69.94%\n",
      "70.07%\n",
      "70.09%\n",
      "70.22%\n",
      "70.23%\n",
      "70.36%\n",
      "70.38%\n",
      "70.51%\n",
      "70.52%\n",
      "70.65%\n",
      "70.66%\n",
      "70.79%\n",
      "70.81%\n",
      "70.94%\n",
      "70.95%\n",
      "71.08%\n",
      "71.10%\n",
      "71.23%\n",
      "71.24%\n",
      "71.37%\n",
      "71.39%\n",
      "71.52%\n",
      "71.53%\n",
      "71.66%\n",
      "71.68%\n",
      "71.81%\n",
      "71.82%\n",
      "71.95%\n",
      "71.97%\n",
      "72.10%\n",
      "72.11%\n",
      "72.24%\n",
      "72.25%\n",
      "72.38%\n",
      "72.40%\n",
      "72.53%\n",
      "72.54%\n",
      "72.67%\n",
      "72.69%\n",
      "72.82%\n",
      "72.83%\n",
      "72.96%\n",
      "72.98%\n",
      "73.11%\n",
      "73.12%\n",
      "73.25%\n",
      "73.27%\n",
      "73.40%\n",
      "73.41%\n",
      "73.54%\n",
      "73.55%\n",
      "73.68%\n",
      "73.70%\n",
      "73.83%\n",
      "73.84%\n",
      "73.97%\n",
      "73.99%\n",
      "74.12%\n",
      "74.13%\n",
      "74.26%\n",
      "74.28%\n",
      "74.41%\n",
      "74.42%\n",
      "74.55%\n",
      "74.57%\n",
      "74.70%\n",
      "74.71%\n",
      "74.84%\n",
      "74.86%\n",
      "74.99%\n",
      "75.00%\n",
      "75.13%\n",
      "75.14%\n",
      "75.27%\n",
      "75.29%\n",
      "75.42%\n",
      "75.43%\n",
      "75.56%\n",
      "75.58%\n",
      "75.71%\n",
      "75.72%\n",
      "75.85%\n",
      "75.87%\n",
      "76.00%\n",
      "76.01%\n",
      "76.14%\n",
      "76.16%\n",
      "76.29%\n",
      "76.30%\n",
      "76.43%\n",
      "76.45%\n",
      "76.58%\n",
      "76.59%\n",
      "76.72%\n",
      "76.73%\n",
      "76.86%\n",
      "76.88%\n",
      "77.01%\n",
      "77.02%\n",
      "77.15%\n",
      "77.17%\n",
      "77.30%\n",
      "77.31%\n",
      "77.44%\n",
      "77.46%\n",
      "77.59%\n",
      "77.60%\n",
      "77.73%\n",
      "77.75%\n",
      "77.88%\n",
      "77.89%\n",
      "78.02%\n",
      "78.03%\n",
      "78.16%\n",
      "78.18%\n",
      "78.31%\n",
      "78.32%\n",
      "78.45%\n",
      "78.47%\n",
      "78.60%\n",
      "78.61%\n",
      "78.74%\n",
      "78.76%\n",
      "78.89%\n",
      "78.90%\n",
      "79.03%\n",
      "79.05%\n",
      "79.18%\n",
      "79.19%\n",
      "79.32%\n",
      "79.34%\n",
      "79.47%\n",
      "79.48%\n",
      "79.61%\n",
      "79.62%\n",
      "79.75%\n",
      "79.77%\n",
      "79.90%\n",
      "79.91%\n",
      "80.04%\n",
      "80.06%\n",
      "80.19%\n",
      "80.20%\n",
      "80.33%\n",
      "80.35%\n",
      "80.48%\n",
      "80.49%\n",
      "80.62%\n",
      "80.64%\n",
      "80.77%\n",
      "80.78%\n",
      "80.91%\n",
      "80.92%\n",
      "81.05%\n",
      "81.07%\n",
      "81.20%\n",
      "81.21%\n",
      "81.34%\n",
      "81.36%\n",
      "81.49%\n",
      "81.50%\n",
      "81.63%\n",
      "81.65%\n",
      "81.78%\n",
      "81.79%\n",
      "81.92%\n",
      "81.94%\n",
      "82.07%\n",
      "82.08%\n",
      "82.21%\n",
      "82.23%\n",
      "82.36%\n",
      "82.37%\n",
      "82.50%\n",
      "82.51%\n",
      "82.64%\n",
      "82.66%\n",
      "82.79%\n",
      "82.80%\n",
      "82.93%\n",
      "82.95%\n",
      "83.08%\n",
      "83.09%\n",
      "83.22%\n",
      "83.24%\n",
      "83.37%\n",
      "83.38%\n",
      "83.51%\n",
      "83.53%\n",
      "83.66%\n",
      "83.67%\n",
      "83.80%\n",
      "83.82%\n",
      "83.95%\n",
      "83.96%\n",
      "84.09%\n",
      "84.10%\n",
      "84.23%\n",
      "84.25%\n",
      "84.38%\n",
      "84.39%\n",
      "84.52%\n",
      "84.54%\n",
      "84.67%\n",
      "84.68%\n",
      "84.81%\n",
      "84.83%\n",
      "84.96%\n",
      "84.97%\n",
      "85.10%\n",
      "85.12%\n",
      "85.25%\n",
      "85.26%\n",
      "85.39%\n",
      "85.40%\n",
      "85.53%\n",
      "85.55%\n",
      "85.68%\n",
      "85.69%\n",
      "85.82%\n",
      "85.84%\n",
      "85.97%\n",
      "85.98%\n",
      "86.11%\n",
      "86.13%\n",
      "86.26%\n",
      "86.27%\n",
      "86.40%\n",
      "86.42%\n",
      "86.55%\n",
      "86.56%\n",
      "86.69%\n",
      "86.71%\n",
      "86.84%\n",
      "86.85%\n",
      "86.98%\n",
      "86.99%\n",
      "87.12%\n",
      "87.14%\n",
      "87.27%\n",
      "87.28%\n",
      "87.41%\n",
      "87.43%\n",
      "87.56%\n",
      "87.57%\n",
      "87.70%\n",
      "87.72%\n",
      "87.85%\n",
      "87.86%\n",
      "87.99%\n",
      "88.01%\n",
      "88.14%\n",
      "88.15%\n",
      "88.28%\n",
      "88.29%\n",
      "88.42%\n",
      "88.44%\n",
      "88.57%\n",
      "88.58%\n",
      "88.71%\n",
      "88.73%\n",
      "88.86%\n",
      "88.87%\n",
      "89.00%\n",
      "89.02%\n",
      "89.15%\n",
      "89.16%\n",
      "89.29%\n",
      "89.31%\n",
      "89.44%\n",
      "89.45%\n",
      "89.58%\n",
      "89.60%\n",
      "89.73%\n",
      "89.74%\n",
      "89.87%\n",
      "89.88%\n",
      "90.01%\n",
      "90.03%\n",
      "90.16%\n",
      "90.17%\n",
      "90.30%\n",
      "90.32%\n",
      "90.45%\n",
      "90.46%\n",
      "90.59%\n",
      "90.61%\n",
      "90.74%\n",
      "90.75%\n",
      "90.88%\n",
      "90.90%\n",
      "91.03%\n",
      "91.04%\n",
      "91.17%\n",
      "91.18%\n",
      "91.32%\n",
      "91.33%\n",
      "91.46%\n",
      "91.47%\n",
      "91.60%\n",
      "91.62%\n",
      "91.75%\n",
      "91.76%\n",
      "91.89%\n",
      "91.91%\n",
      "92.04%\n",
      "92.05%\n",
      "92.18%\n",
      "92.20%\n",
      "92.33%\n",
      "92.34%\n",
      "92.47%\n",
      "92.49%\n",
      "92.62%\n",
      "92.63%\n",
      "92.76%\n",
      "92.77%\n",
      "92.90%\n",
      "92.92%\n",
      "93.05%\n",
      "93.06%\n",
      "93.19%\n",
      "93.21%\n",
      "93.34%\n",
      "93.35%\n",
      "93.48%\n",
      "93.50%\n",
      "93.63%\n",
      "93.64%\n",
      "93.77%\n",
      "93.79%\n",
      "93.92%\n",
      "93.93%\n",
      "94.06%\n",
      "94.08%\n",
      "94.21%\n",
      "94.22%\n",
      "94.35%\n",
      "94.36%\n",
      "94.49%\n",
      "94.51%\n",
      "94.64%\n",
      "94.65%\n",
      "94.78%\n",
      "94.80%\n",
      "94.93%\n",
      "94.94%\n",
      "95.07%\n",
      "95.09%\n",
      "95.22%\n",
      "95.23%\n",
      "95.36%\n",
      "95.38%\n",
      "95.51%\n",
      "95.52%\n",
      "95.65%\n",
      "95.66%\n",
      "95.79%\n",
      "95.81%\n",
      "95.94%\n",
      "95.95%\n",
      "96.08%\n",
      "96.10%\n",
      "96.23%\n",
      "96.24%\n",
      "96.37%\n",
      "96.39%\n",
      "96.52%\n",
      "96.53%\n",
      "96.66%\n",
      "96.68%\n",
      "96.81%\n",
      "96.82%\n",
      "96.95%\n",
      "96.97%\n",
      "97.10%\n",
      "97.11%\n",
      "97.24%\n",
      "97.25%\n",
      "97.38%\n",
      "97.40%\n",
      "97.53%\n",
      "97.54%\n",
      "97.67%\n",
      "97.69%\n",
      "97.82%\n",
      "97.83%\n",
      "97.96%\n",
      "97.98%\n",
      "98.11%\n",
      "98.12%\n",
      "98.25%\n",
      "98.27%\n",
      "98.40%\n",
      "98.41%\n",
      "98.54%\n",
      "98.55%\n",
      "98.68%\n",
      "98.70%\n",
      "98.83%\n",
      "98.84%\n",
      "98.97%\n",
      "98.99%\n",
      "99.12%\n",
      "99.13%\n",
      "99.26%\n",
      "99.28%\n",
      "99.41%\n",
      "99.42%\n",
      "99.55%\n",
      "99.57%\n",
      "99.70%\n",
      "99.71%\n",
      "99.84%\n",
      "99.86%\n",
      "99.99%\n",
      "100%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import clear_output\n",
    "\n",
    "len_dataset = len(test_dataset)\n",
    "with open(\"answer.csv\", \"w\") as file:\n",
    "    writer = csv.writer(file, delimiter=\",\")\n",
    "    writer.writerow([\"id\", \"target_feature\"])\n",
    "    for index, image in enumerate(test_dataset):\n",
    "        with torch.no_grad():\n",
    "            pred_y = model(image.unsqueeze(0))\n",
    "        answer = max(((n, i) for i, n in enumerate(pred_y[0])), key=lambda x: x[0])[1]\n",
    "        writer.writerow([index, answer])\n",
    "        if index % 10 == 0 or index % 10 == 9:\n",
    "            print(f\"{(index / len_dataset) * 100:.2f}%\")\n",
    "print(\"100%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T08:59:56.872604Z",
     "start_time": "2023-12-08T08:56:05.012167Z"
    }
   },
   "id": "e5f69f0d8daecbd5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-07T20:51:09.702684Z"
    }
   },
   "id": "d2eca2918f0d61d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
